---
title: 极客时间MYSQL45讲
categories: 
  - 数据库
tags: 
  - MYSQL
  - 关系型数据库
date: 2023-02-21 14:21:38
index_img: /img/article/mysql.png
permalink: /pages/8dbea9/
author: 
  name: 爱写bug的小邓程序员
  link: https://github.com/dengerpu
---

## 01 | 基础架构：一条SQL查询语句是如何执行的？

mysql逻辑架构图

![image-20230227125340769](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/image-20230227125340769.png)

大体来说，MySQL 可以分为 Server 层和存储引擎层两部分。Server 层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。

## 04 | 深入浅出索引（上）

索引的常见模型：哈希表、有序数组和搜索树

**哈希表：**哈希表是一种以键 - 值（key-value）存储数据的结构，我们只要输入待查找的键即 key，就可以找到其对应的值即 Value。哈希的思路很简单，把值放在数组里，用一个哈希函数把 key 换算成一个确定的位置，然后把 value 放在数组的这个位置。

![image-20230228212916807](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/image-20230228212916807.png)

优点：索引维护和单值查询

缺点：不适用于区间查询

**有序数组 :**  使用二分查找的话，时间复杂度：o(log(n))

![image-20230228213552632](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/image-20230228213552632.png)

优点：等值查找和范围查找都很优秀

缺点：不适合更新删除增加

**有序数组索引只适用于静态存储引擎**

**二叉搜索树：**

![image-20230228214013512](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/image-20230228214013512.png)

查询和更新都是 o(log(n))

异同比较: 哈希表 : 优点在于索引维护和单值查询,缺点在于范围查询 有序数组 : 优点在于单值查询和范围查询,缺点在于索引维护,不便于新索引的插入,适合静态表 搜索树 : 查询和维护效率都不错,但是如果树的高度太高,那么磁盘IO开销会很大 B+树 : 很好的解决了搜索树的问题,高度一般只有2到3层,并且B+树的叶子节点以双向链表的形式接连,更加适合范围查询



MyISAM和InnoDB两个存储引擎的索引实现方式都是基于B+树，但是两者的实现不同。 MyISAM：叶节点的data域存放的是数据记录的地址。因此，MyISAM中索引检索的算法为首先按照B+Tree搜索算法搜索索引，如果指定的Key存在，则取出其data域的值，然后以data域的值为地址，读取相应数据记录。MyISAM的索引方式也叫做“非聚集”的。MyISAM的辅助索引（Secondary key）在结构上没有任何区别，只是主索引要求key是唯一的，而辅助索引的key可以重复。 InnoDB：InnoDB的数据文件本身就是索引文件。这棵树的叶节点data域保存了完整的数据记录。InnoDB的辅助索引data域存储相应记录主键的值而不是地址。换句话说，InnoDB的所有辅助索引都引用主键作为data域。

**关于 InnoDB 的表结构：** 1.在 InnoDB 中，每一张表其实就是多个 B+ 树，即一个主键索引树和多个非主键索引树。 2.执行查询的效率，使用主键索引 > 使用非主键索引 > 不使用索引。 3.如果不使用索引进行查询，则从主索引 B+ 树的叶子节点进行遍历。

![image-20230228214811600](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/image-20230228214811600.png)

![image-20230228214824544](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/image-20230228214824544.png)

索引类型分为==主键索引==和==非主键索引==

**主键索引**的叶子节点存的是整行数据。在 InnoDB 里，主键索引也被称为聚簇索引（clustered index）。

**非主键索引**的叶子节点内容是主键的值。在 InnoDB 里，非主键索引也被称为二级索引（secondary index）。

> 基于主键索引和普通索引的查询有什么区别？
>
> ![image-20230228215835350](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/image-20230228215835350.png)

索引维护：

自增主键是指自增列上定义的主键，在建表语句中一般是这么定义的： NOT NULL PRIMARY KEY AUTO_INCREMENT。

用业务逻辑的字段做主键，则往往不容易保证有序插入，这样写数据成本相对较高。

> 主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。
>
> ![image-20230301143005806](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/image-20230301143005806.png)

## 05 | 深入浅出索引（下）

![image-20230301143624039](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/image-20230301143624039.png)

![image-20230301143658836](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/image-20230301143658836.png)

### 覆盖索引

```mysql

mysql> create table T (
ID int primary key,
k int NOT NULL DEFAULT 0, 
s varchar(16) NOT NULL DEFAULT '',
index k(k))
engine=InnoDB;

insert into T values(100,1, 'aa'),(200,2,'bb'),(300,3,'cc'),(500,5,'ee'),(600,6,'ff'),(700,7,'gg');
```

如果执行的语句是 select ID from T where k between 3 and 5，这时只需要查 ID 的值，而 ID 的值已经在 k 索引树上了，因此可以直接提供查询结果，不需要回表。也就是说，在这个查询里面，索引 k 已经“覆盖了”我们的查询需求，我们称为覆盖索引。

> 由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。
>
> **覆盖索引就是在这次的查询中，所要的数据已经在这棵索引树的叶子结点上了**

### 最左前缀原则

> **最左前缀可以是联合索引的最左 N 个字段，也可以是字符串索引的最左 M 个字符。**
>
> ![image-20230301145931316](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/image-20230301145931316.png)

联合索引(A, B)意味着不需要建立A的索引了，因为这个联合索引意味着建立了(A,B)和(A)这两种索引

![image-20230301150621375](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/image-20230301150621375.png)

### 索引下推

MySQL 5.6 引入的索引下推优化（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。

![image-20230301151358937](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/image-20230301151358937.png)

无索引下推执行流程

![image-20230301151506781](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/image-20230301151506781.png)

索引下推执行流程

![image-20230301151555171](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/image-20230301151555171.png)

### 总结

> ![image-20230301151745621](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/image-20230301151745621.png)

## 06 | 全局锁和表锁 ：给表加个字段怎么有这么多阻碍？

数据库锁设计的初衷是处理并发问题。作为多用户共享的资源，当出现并发访问的时候，数据库需要合理地控制资源的访问规则。而锁就是用来实现这些访问规则的重要数据结构。

根据加锁的范围，MySQL 里面的锁大致可以分成全局锁、表级锁和行锁三类。

> 全局锁和表级锁实在server层实现的
>
> MySQL的行锁是在引擎层由各个引擎自己实现的； MyISAM引擎不支持行锁，InnoDB支持行锁， 这也是MyISAM被InnoDB替代的重要原因之一。

### 全局锁

顾名思义，全局锁就是对整个数据库实例加锁。MySQL 提供了一个加全局读锁的方法，命令是 Flush tables with read lock (FTWRL)。当你需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句。

**全局锁的典型使用场景是，做全库逻辑备份。**也就是把整库每个表都 select 出来存成文本。

缺点：

* 如果你在主库上备份，那么在备份期间都不能执行更新，业务基本上就得停摆；
* 如果你在从库上备份，那么备份期间从库不能执行主库同步过来的 binlog，会导致主从延迟。

如果不在全局锁，因为不同表之间的执行顺序不同进而备份的时间不同。如果某个表在这个时间差中进行了更新并且成功被备份，而与其有关联的表已经在之前备份完毕已无法更新。此时就发生数据不一致。

官方自带的逻辑备份工具是 mysqldump。当 mysqldump 使用参数–single-transaction 的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于 MVCC 的支持，这个过程中数据是可以正常更新的。

你一定在疑惑，有了这个功能，为什么还需要 FTWRL 呢？**一致性读是好，但前提是引擎要支持这个隔离级别。**比如，对于 MyISAM 这种不支持事务的引擎，如果备份过程中有更新，总是只能取到最新的数据，那么就破坏了备份的一致性。这时，我们就需要使用 FTWRL 命令了。

所以，**single-transaction 方法只适用于所有的表使用事务引擎的库。**如果有的表使用了不支持事务的引擎，那么备份就只能通过 FTWRL 方法。这往往是 DBA 要求业务开发人员使用 InnoDB 替代 MyISAM 的原因之一。



**既然要全库只读，为什么不使用 set global readonly=true 的方式呢？**确实 readonly 方式也可以让全库进入只读状态，但我还是会建议你用 FTWRL 方式，

主要有两个原因：

* 一是，在有些系统中，readonly 的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库。因此，修改 global 变量的方式影响面更大，我不建议你使用。

* 二是，在异常处理机制上有差异。如果执行 FTWRL 命令之后由于客户端发生异常断开，那么 MySQL 会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为 readonly 之后，如果客户端发生异常，则数据库就会一直保持 readonly 状态，这样会导致整个库长时间处于不可写状态，风险较高。

### 表级锁

MySQL 里面表级别的锁有两种：一种是表锁，一种是元数据锁（meta data lock，MDL)。

**表锁的语法是 lock tables … read/write。**与 FTWRL 类似，可以用 unlock tables 主动释放锁，也可以在客户端断开的时候自动释放。需要注意，lock tables 语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。

举个例子, 如果在某个线程 A 中执行 lock tables t1 read, t2 write; 这个语句，则其他线程写 t1、读写 t2 的语句都会被阻塞。同时，线程 A 在执行 unlock tables 之前，也只能执行读 t1、读写 t2 的操作。连写 t1 都不允许，自然也不能访问其他表。

在还没有出现更细粒度的锁的时候，表锁是最常用的处理并发的方式。而对于 InnoDB 这种支持行锁的引擎，一般不使用 lock tables 命令来控制并发，毕竟锁住整个表的影响面还是太大。

**另一类表级的锁是 MDL（metadata lock)。**MDL 不需要显式使用，在访问一个表的时候会被自动加上。MDL 的作用是，保证读写的正确性。你可以想象一下，如果一个查询正在遍历一个表中的数据，而执行期间另一个线程对这个表结构做变更，删了一列，那么查询线程拿到的结果跟表结构对不上，肯定是不行的。

因此，在 MySQL 5.5 版本中引入了 MDL，当对一个表做增删改查操作的时候，加 MDL 读锁；当要对表做结构变更操作的时候，加 MDL 写锁。

> 读写表数据的时候，不允许对表结构之类的东西做任何变更。![image-20230301161143026](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/image-20230301161143026.png)

## 07 | 行锁功过：怎么减少行锁对性能的影响？

MySQL 的行锁是在引擎层由各个引擎自己实现的。但并不是所有的引擎都支持行锁，比如 MyISAM 引擎就不支持行锁。不支持行锁意味着并发控制只能使用表锁，对于这种引擎的表，同一张表上任何时刻只能有一个更新在执行，这就会影响到业务并发度。InnoDB 是支持行锁的，这也是 MyISAM 被 InnoDB 替代的重要原因之一。

> 顾名思义，行锁就是针对数据表中行记录的锁。这很好理解，比如事务 A 更新了一行，而这时候事务 B 也要更新同一行，则必须等事务 A 的操作完成后才能进行更新。

![image-20230301162406256](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/image-20230301162406256.png)

> **在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。**
>
> ![image-20230301162531760](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/image-20230301162531760.png)

![image-20230301162806526](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/image-20230301162806526.png)

事务在执行的时候，并不是一次性把所有行锁都持有，而是执行到哪一行就拿哪一行的锁。等到最后commit的时候，一起释放。

### 死锁和死锁检测

![image-20230301192253412](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/image-20230301192253412.png)

死锁解决策略：

* 一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数 `innodb_lock_wait_timeout `来设置。
* 另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 `innodb_deadlock_detect `设置为 on，表示开启这个逻辑。

> innodb默认锁等待时间是50s
>
> ![image-20230301192912067](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/image-20230301192912067.png)

### 总结

> 如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁的申请时机尽量往后放。

## 08 | 事务到底是隔离的还是不隔离的？

> `begin/start transaction`：这个操作不会启动一个事务，这个操作之后第一个对数据库的操作才会真正启动一个事务。
>
> ![image-20230301200524843](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/image-20230301200524843.png)

```mysql
mysql> CREATE TABLE `t` (
  `id` int(11) NOT NULL,
  `k` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB;
insert into t(id, k) values(1,1),(2,2);
```

![image-20230302160749953](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/image-20230302160749953.png)

> 事务 C 没有显式地使用 begin/commit，表示这个 update 语句本身就是一个事务，语句完成的时候会自动提交。事务 B 在更新了行之后查询 ; 事务 A 在一个只读事务中查询，并且时间顺序上是在事务 B 的查询之后。
>
> 如果我告诉你**事务 B 查到的 k 的值是 3，而事务 A 查到的 k 的值是 1**
>
> ![image-20230302160950638](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/image-20230302160950638.png)

* 一个是 view。它是一个用查询语句定义的虚拟表，在调用的时候执行查询语句并生成结果。创建视图的语法是 create view … ，而它的查询方法与表一样。

  * ```mysql
    CREATE VIEW <视图名> AS <SELECT语句>
    ```

  * 另一个是 InnoDB 在实现 MVCC 时用到的一致性读视图，即 consistent read view，用于支持 RC（Read Committed，读提交）和 RR（Repeatable Read，可重复读）隔离级别的实现。

一个数据版本，对于一个事务视图来说，除了自己的更新总是可见以外，有三种情况：

1. 版本未提交，不可见；
2. 版本已提交，但是是在视图创建后提交的，不可见；
3. 版本已提交，而且是在视图创建前提交的，可见。

![image-20230302163019357](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/image-20230302163019357.png)

**更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）。**

## 09 | 普通索引和唯一索引，应该怎么选择？

### 查询过程

* 对于普通索引来说，查找到满足条件的第一个记录 (5,500) 后，需要查找下一个记录，直到碰到第一个不满足 k=5 条件的记录。
* 对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索。

> **普通索引存放的索引是可重复的**，因此查找到满足的第一个记录的时候还是要继续往下查找；而对于**唯一索引，因为是唯一的，不重复，**所以找到满足的就可以结束了。 俩者的性能差距主要体现在，如果要查找的正好处于一个数据页的末尾上。具体来说，如果是唯一索引，那么就直接结束，因为后面肯定不会在出现满足条件的索引了；而对于普通索引来说，就还得从磁盘中取一个数据页到内存当中，多了一次IO操作，性能也自然就下去了。另一个方面，唯一索引只需判断一次，普通索引还需要向后继续寻找，直到不满足才结束。当然这对于CPU来说影响较小，主要问题还是在一个数据页的末尾的情况下。 (如果不在数据页的末尾，就不需要进行IO取下一页的数据，此时性能差距微乎其微，所以一般来说性能差距很小) 因为遍历的链表是有序的，所以往后一个不满足，就都不满足了，没必要往下继续遍历到最后一个啦

### 更新过程

当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InnoDB 会将这些更新操作缓存在 change buffer 中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行 change buffer 中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。

> change buffer
>
> 数据在内存中直接更新，不在内存的话change buffer记录更新操作，然后定时刷新到磁盘或者读取数据的时候更新读入内存的数据并刷新，
>
> ![image-20230302170354948](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/image-20230302170354948.png)

​	对于唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束。比如，要插入 (4,400) 这个记录，就要先判断现在表中是否已经存在 k=4 的记录，而这必须要将数据页读入内存才能判断。如果都已经读入到内存了，那直接更新内存会更快，就没必要使用 change buffer 了。

​	显然，如果能够将更新操作先记录在 change buffer，减少读磁盘，语句的执行速度会得到明显的提升。而且，数据读入内存是需要占用 buffer pool 的，所以这种方式还能够避免占用内存，提高内存利用率。

**唯一索引的更新就不能使用 change buffer，实际上也只有普通索引可以使用。**

> 因此, 普通索引和唯一索引的查询性能几乎一样, 但是写性能是普通索引快, 因为可以用到change buffer, 唯一索引会导致内存命中率下降

### change buffer 的使用场景

changebuffer 适用场景, 写多查询少的场景,如果查询多,在查询数据的时候会将change buffer中维护的数据更新到磁盘中,随机访问io的次数只多不少,而且也增加了change buffer的维护代价

### 索引选择和实践

​	两类索引在查询能力上是没差别的，主要考虑的是对更新性能的影响。所以，我建议你尽量**选择普通索引**。

​	在实际使用中，你会发现，普通索引和 change buffer 的配合使用，对于数据量大的表的更新优化还是很明显的。

​	特别地，在使用机械硬盘时，change buffer 这个机制的收效是非常显著的。所以，当你有一个类似“历史数据”的库，并且出于成本考虑用的是机械硬盘时，那你应该特别关注这些表里的索引，尽量使用普通索引，然后把 change buffer 尽量开大，以确保这个“历史数据”表的数据写入速度。

### change buffer 和 redo log

**redo log 主要节省的是随机写磁盘的 IO 消耗（转成顺序写），而 change buffer 主要节省的则是随机读磁盘的 IO 消耗。**

## 10 | MySQL为什么有时候会选错索引？

mysql对索引的使用是由mysql的server层的优化器决定的；

```mysql
CREATE TABLE `t` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `a` int(11) DEFAULT NULL,
  `b` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `a` (`a`),
  KEY `b` (`b`)
) ENGINE=InnoDB;
```

查询

```mysql
explain select * from t where a between 10000 and 20000;
```

![img](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/2cfce769551c6eac9bfbee0563d48fe3.png)

**优化器选择索引的依据： 1.扫描行数 2.基数 3.临时表 4.是否排序**

### 扫描行数是怎么判断的？

MySQL 在真正开始执行语句之前，并不能精确地知道满足这个条件的记录有多少条，而只能根据统计信息来估算记录数。

> 索引区分度越高，估算扫描记录数越准，选对索引的概率就越高。

### MySQL 是怎样得到索引的基数的呢？

查看索引的基数

```mysql
show index
```

![img](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/16dbf8124ad529fec0066950446079d4.png)

>  mysql采用采用统计来得到索引的基数。 采样统计的时候，InnoDB 默认会选择 N 个数据页，统计这些页面上的不同值，得到一个平均值，然后乘以这个索引的页面数，就得到了这个索引的基数。 而数据表是会持续更新的，索引统计信息也不会固定不变。所以，当变更的数据行数超过 1/M 的时候，会自动触发重新做一次索引统计。 在 MySQL 中，有两种存储索引统计的方式，可以通过设置参数 innodb_stats_persistent 的值来选择： 设置为 on 的时候，表示统计信息会持久化存储。这时，默认的 N 是 20，M 是 10。 设置为 off 的时候，表示统计信息只存储在内存中。这时，默认的 N 是 8，M 是 16。

analyze table t 命令，可以用来重新统计索引信息

![img](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/209e9d3514688a3bcabbb75e54e1e49c.png)

### 索引选择异常和处理

一种方法是，像我们第一个例子一样，**采用 force index 强行选择一个索引。**MySQL 会根据词法解析的结果分析出可能可以使用的索引作为候选项，然后在候选列表中依次判断每个索引需要扫描多少行。如果 force index 指定的索引在候选索引列表中，就直接选择这个索引，不再评估其他索引的执行代价。

![img](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/9582401a6bed6cb8fd803c9555750b54.png)

但其实使用 force index 最主要的问题还是变更的及时性。因为选错索引的情况还是比较少出现的，所以开发的时候通常**不会先写上 force index**。而是等到线上出现问题的时候，你才会再去修改 SQL 语句、加上 force index。但是修改之后还要测试和发布，对于生产系统来说，这个过程不够敏捷。

第二种方法就是，我们可以考虑修改语句，引导 MySQL 使用我们期望的索引。

第三种方法是，在有些场景下，我们可以新建一个更合适的索引，来提供给优化器做选择，或删掉误用的索引。

> 使用错了索引。
>
> 1. 可以使用`force index(key)`进行校正。
> 2. 通过修改sql语句诱导优化器选择正确的索引，因为优化器选择索引会考虑三个因素，扫描函数、临时表和排序。
> 3. 重新建立一个更合适的索引。

## 11 | 怎么给字符串字段加索引？

几乎所有的系统都支持邮箱登录，如何在邮箱这样的字段上建立合理的索引，是我们今天要讨论的问题。

MySQL 是支持前缀索引的，也就是说，你可以定义字符串的一部分作为索引。默认地，如果你创建索引的语句不指定前缀长度，那么索引就会包含整个字符串。

```mysql
mysql> alter table SUser add index index1(email); -- 索引包括整个字符串

mysql> alter table SUser add index index2(email(6)); -- 索引只取前6个字节
```

![image-20230304211935479](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/image-20230304211935479.png)

email(6)**占用的空间会更小**，这就是使用**前缀索引**的优势,但是**可能会增加额外的记录扫描次数。**

![image-20230304212215989](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/image-20230304212215989.png)

![image-20230304212231038](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/image-20230304212231038.png)

通过这个对比，你很容易就可以发现，使用前缀索引后，可能会导致查询语句读数据的次数变多。

**使用前缀索引，定义好长度，就可以做到既节省空间，又不用额外增加太多的查询成本。**

### 当要给字符串创建前缀索引时，有什么方法能够确定我应该使用多长的前缀呢？

在建立索引时关注的是区分度，区分度越高越好。因为区分度越高，意味着重复的键值越少。

![image-20230304212532571](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/image-20230304212532571.png)

### 前缀索引对覆盖索引的影响

![image-20230304213336370](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/image-20230304213336370.png)

使用前缀索引就用不上覆盖索引对查询性能的优化了，这也是你在选择是否使用前缀索引时需要考虑的一个因素。

### 其他方式

比如，我们国家的身份证号，一共 18 位，其中前 6 位是地址码，所以同一个县的人的身份证号前 6 位一般会是相同的。假设你维护的数据库是一个市的公民信息系统，这时候如果对身份证号做长度为 6 的前缀索引的话，这个索引的区分度就非常低了。按照我们前面说的方法，可能你需要创建长度为 12 以上的前缀索引，才能够满足区分度要求。但是，索引选取的越长，占用的磁盘空间就越大，相同的数据页能放下的索引值就越少，搜索的效率也就会越低。

#### 第一种方式是使用倒序存储。

如果你存储身份证号的时候把它倒过来存，每次查询的时候，你可以这么写：

```mysql
select field_list from t where id_card = reverse('input_id_card_string');
```

由于身份证号的最后 6 位没有地址码这样的重复逻辑，所以最后这 6 位很可能就提供了足够的区分度。当然了，实践中你不要忘记使用 count(distinct) 方法去做个验证。

#### 第二种方式是使用 hash 字段。

你可以在表上再创建一个整数字段，来保存身份证的校验码，同时在这个字段上创建索引。

```mysql
mysql> alter table t add id_card_crc int unsigned, add index(id_card_crc);
```

然后每次插入新记录的时候，都同时用 crc32() 这个函数得到校验码填到这个新字段。由于校验码可能存在冲突，也就是说两个不同的身份证号通过 crc32() 函数得到的结果可能是相同的，所以你的查询语句 where 部分要判断 id_card 的值是否精确相同。

```mysql
mysql> select field_list from t where id_card_crc=crc32('input_id_card_string') and id_card='input_id_card_string'
```

这样，索引的长度变成了 4 个字节，比原来小了很多。

### 使用倒序存储和使用 hash 字段这两种方法的异同点。

首先，它们的相同点是，**都不支持范围查询**。倒序存储的字段上创建的索引是按照倒序字符串的方式排序的，已经没有办法利用索引方式查出身份证号码在[ID_X, ID_Y]的所有市民了。同样地，hash 字段的方式也只能支持等值查询。

1. 从占用的额外空间来看，倒序存储方式在主键索引上，不会消耗额外的存储空间，而 hash 字段方法需要增加一个字段。当然，倒序存储方式使用 4 个字节的前缀长度应该是不够的，如果再长一点，这个消耗跟额外这个 hash 字段也差不多抵消了。
2. 在 CPU 消耗方面，倒序方式每次写和读的时候，都需要额外调用一次 reverse 函数，而 hash 字段的方式需要额外调用一次 crc32() 函数。如果只从这两个函数的计算复杂度来看的话，reverse 函数额外消耗的 CPU 资源会更小些。
3. 从查询效率上看，使用 hash 字段方式的查询性能相对更稳定一些。因为 crc32 算出来的值虽然有冲突的概率，但是概率非常小，可以认为每次查询的平均扫描行数接近 1。而倒序存储方式毕竟还是用的前缀索引的方式，也就是说还是会增加扫描行数。

> 1. 直接创建完整索引，这样可能比较占用空间；
> 2. 创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引；
> 3. 倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题；
> 4. 创建 hash 字段索引，查询性能稳定，有额外的存储和计算消耗，跟第三种方式一样，都不支持范围扫描。

> 1.为什么需要优化字符串上的索引 如果字符串较长，索引字段占用内存空间大，B+树高度较高，这样查询IO次数较多，耗时长。 个人认为未出现性能瓶颈，不需要过度优化，全字段索引也ok。 
>
> 2.优化方法及优缺点、适用场景 方法一：前缀索引 概念：在建立索引的时候指定索引长度，且该长度的字段区分度高 优点： a. 相比全字段索引，每页存储的索引更多，查询索引IO次数少，效率高。即既节省了内存空间，又提高了查询效率。 缺点： a. 指定索引长度的区分度低的话，扫描主键索引次数就会多，效率低； b. 不会使用覆盖索引，即使索引长度定义为全字段，也会去主键索引查询 适用场景：前缀索引区分度高 方法二：倒序存储 概念：字段保存的时候反序存储 优点：同前缀索引 缺点： a.只适用于等值查询，不适用于范围、模糊查询。 b.每次保存、查询时需调用reverse()函数； c.若后缀索引区分度低，扫描行数会增多。 适用场景：索引字段后缀区分度高，前缀区分度低。 方法三：添加hash字段，作为索引 概念：在表中添加一个hash字段并加索引，用于存储索引字段的哈希值如使用crc32()哈希函数，每次查询时先计算出字段的hash值，再利用hash字段查询。可能存在hash冲突，所以where需要加索引字段字段的等值条件。 优点：哈希函数冲突概率低的话，平均扫描行数接近1。 缺点：只适用于等值查询，不适用于范围、模糊查询。 适用场景：只适用于等值查询，不适用范围查询或模糊查询。

## 12 | 为什么我的MySQL会“抖”一下？

而 MySQL 偶尔“抖”一下的那个瞬间，可能就是在刷脏页（flush）。

当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“**脏页**”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“**干净页**”。

## 13 | 为什么表数据删掉一半，表文件大小不变？

8.0以前：表结构定义存磁盘文件里（.frm文件）； 8.0及以后：表结构定义存数据库表里（系统数据表）。

### 参数 innodb_file_per_table

1. 这个参数设置为 `OFF` 表示的是，表的数据放在系统共享表空间，也就是跟数据字典放在一起；
2. 这个参数设置为` ON `表示的是，每个 InnoDB 表数据存储在一个以 .ibd 为后缀的文件中。

**从 MySQL 5.6.6 版本开始，它的默认值就是 ON 了。**

我建议你不论使用 MySQL 的哪个版本，都将这个值设置为 ON。因为，一个表单独存储为一个文件更容易管理，而且在你不需要这个表的时候，通过 drop table 命令，系统就会直接删除这个文件。而如果是放在共享表空间中，即使表删掉了，空间也是不会回收的。

### 数据删除流程

![image-20230307141530304](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/202303071415524.png)

记录的复用，只限于符合范围条件的数据。比如上面的这个例子，R4 这条记录被删除后，如果插入一个 ID 是 400 的行，可以直接复用这个空间。但如果插入的是一个 ID 是 800 的行，就不能复用这个位置了。

而当整个页从 B+ 树里面摘掉以后，可以复用到任何位置。以图 1 为例，如果将数据页 page A 上的所有记录删除以后，page A 会被标记为可复用。这时候如果要插入一条 ID=50 的记录需要使用新页的时候，page A 是可以被复用的。

innodb 中对数据行的删除并不会真正的将其删除，设置行的deleted_flag 值为1，并将当前这条行记录通过next_record 链接到垃圾链表中，这个链表不会占用的空间不会被释放，而是停留在空间中，用于后序插入数据时空间复用。到这里就可以得出结论：**当删除数据页中的行时，本质上是不会释放内存的，所有删除之后变文件的大小基本不变**

delete 命令其实只是把记录的位置，或者数据页标记为了“可复用”，但磁盘文件的大小是不会变的。也就是说，通过 delete 命令是不能回收表空间的。这些可以复用，而没有被使用的空间，看起来就像是“**空洞**”。

造成空洞的原因：

1. 删除记录 
2. 插入记录 
3. 更新索引值 (删除一个旧的值，再插入一个新值)



![image-20230307142551156](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/202303071425313.png)

可以看到，由于 page A 满了，再插入一个 ID 是 550 的数据时，就不得不再申请一个新的页面 page B 来保存数据了。页分裂完成后，page A 的末尾就留下了空洞（注意：实际上，可能不止 1 个记录的位置是空洞）。

空洞的原因：

 ①删除表记录，被删除的记录只是被标记删除，索引值所在的空间能被复用，但是没有真正的删除。 

②新增表记录，如果索引的值是随机分散的，那么会造成数据页的分裂，也会造成空洞 

③更新索引上的值，实际上是把旧值标记为删除，然后新增一个新值，旧值虽然能被复用，但是还是造成了空洞

### 重建表

如果你现在有一个表 A，需要做空间收缩，为了把表中存在的空洞去掉，你可以怎么做呢？

你可以新建一个与表 A 结构相同的表 B，然后按照主键 ID 递增的顺序，把数据一行一行地从表 A 里读出来再插入到表 B 中。由于表 B 是新建的表，所以表 A 主键索引上的空洞，在表 B 中就都不存在了。显然地，表 B 的主键索引更紧凑，数据页的利用率也更高。如果我们把表 B 作为临时表，数据从表 A 导入表 B 的操作完成后，用表 B 替换 A，从效果上看，就起到了收缩表 A 空间的作用。

你可以使用 `alter table A engine=InnoDB` 命令来重建表。在 MySQL 5.5 版本之前，这个命令的执行流程跟我们前面描述的差不多，区别只是这个临时表 B 不需要你自己创建，MySQL 会自动完成转存数据、交换表名、删除旧表的操作。

![image-20230307143249368](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/202303071432494.png)

花时间最多的步骤是往临时表插入数据的过程，如果在这个过程中，有新的数据要写入到表 A 的话，就会造成**数据丢失**。因此，在整个 DDL 过程中，表 A 中不能有更新。也就是说，这个 DDL 不是 Online 的。

MySQL 5.6 版本开始引入的 Online DDL，对这个操作流程做了优化。

引入了 Online DDL 之后，重建表的流程：

1. 建立一个临时文件，扫描表 A 主键的所有数据页；
2. 用数据页中表 A 的记录生成 B+ 树，存储到临时文件中；
3. 生成临时文件的过程中，将所有对 A 的操作记录在一个日志文件（row log）中，对应的是图中 state2 的状态；
4. 临时文件生成后，将日志文件中的操作应用到临时文件，得到一个逻辑数据上与表 A 相同的数据文件，对应的就是图中 state3 的状态；
5. 用临时文件替换表 A 的数据文件。

![image-20230307143545719](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/202303071435959.png)

Online DDL 其实是会先获取MDL写锁, 再退化成MDL读锁；但MDL写锁持有时间比较短，所以可以称为Online； 而MDL读锁，不阻止数据增删查改，但会阻止其它线程修改表结构；

如果想要比较安全的操作的话**GitHub 开源的 gh-ost **一个开源的缩小表空间工具

### Online 和 inplace

在存储引擎中实现，对于server端来说，无感知，这种方式叫做**inplace**

根据表 A 重建出来的数据是放在“tmp_file”里的，这个临时文件是 InnoDB 在内部创建出来的。整个 DDL 过程都在 InnoDB 内部完成。对于 server 层来说，没有把数据挪动到临时表，是一个“原地”操作，这就是“inplace”名称的来源。

**如果你有一个 1TB 的表，现在磁盘间是 1.2TB，能不能做一个 inplace 的 DDL 呢？**

答案是不能。因为，tmp_file 也是要占用临时空间的。

## 14 | count(*)这么慢，我该怎么办？

### count(*) 的实现方式

* MyISAM 引擎把一个表的总行数存在了磁盘上，因此执行 count(*) 的时候会直接返回这个数，效率很高；
* 而 InnoDB 引擎就麻烦了，它执行 count(*) 的时候，需要把数据一行一行地从引擎里面读出来，然后累积计数。

> MyISAM count 是存储在硬盘，这只是无条件查询的时候，如果有where条件，也是和InnoDB一样

**那为什么 InnoDB 不跟 MyISAM 一样，也把数字存起来呢？**

这是因为即使是在同一个时刻的多个查询，由于多版本并发控制（MVCC）的原因，InnoDB 表“应该返回多少行”也是不确定的。

> InnoDB 由于多版本控制的机制，是不能由一个固定的数存放行数，因为同一时刻可能会有不同事务访问不同版本的数据

InnoDB 是索引组织表，主键索引树的叶子节点是数据，而普通索引树的叶子节点是主键值。所以，普通索引树比主键索引树小很多。对于 count(*) 这样的操作，遍历哪个索引树得到的结果逻辑上都是一样的。因此，MySQL 优化器会找到最小的那棵树来遍历。在保证逻辑正确的前提下，尽量减少扫描的数据量，是数据库系统设计的通用法则之一。

> show table status 得到的 rows 是预估值，这个预估值是根据随机采样法计算出来的，MySQL会随机取N页数据，计算出每页中不同的记录数，合起来求每页的平均值，最后乘以总页数得到的就是预估值，不是扫描所有的行计算的。 这个预估值是否接近真实值取决于索引字段的区分度和索引数据页是否紧凑，如果存在也分裂、索引空洞都会影响预估值的准确性。

* MyISAM 表虽然 count(*) 很快，但是不支持事务；
* show table status 命令虽然返回很快，但是不准确；
* InnoDB 表直接 count(*) 会遍历全表，虽然结果准确，但会导致性能问题。

**如果你现在有一个页面经常要显示交易系统的操作记录总数，到底应该怎么办呢？**

答案是，我们只能自己计数。

### 用缓存系统保存计数

可以用一个 Redis 服务来保存这个表的总行数。这个表每被插入一行 Redis 计数就加 1，每被删除一行 Redis 计数就减 1。

Redis 的数据不能永久地留在内存里，所以你会找一个地方把这个值定期地持久化存储起来。但即使这样，仍然可能丢失更新。试想如果刚刚在数据表中插入了一行，Redis 中保存的值也加了 1，然后 Redis 异常重启了，重启后你要从存储 redis 数据的地方把这个值读回来，而刚刚加 1 的这个计数操作却丢失了。当然了，这还是有解的。比如，Redis 异常重启以后，到数据库里面单独执行一次 count(*) 获取真实的行数，再把这个值写回到 Redis 里就可以了。异常重启毕竟不是经常出现的情况，这一次全表扫描的成本，还是可以接受的。

**将计数保存在缓存系统中的方式，还不只是丢失更新的问题。即使 Redis 正常工作，这个值还是逻辑上不精确的。**

> 这里主要原因是因为“MySQL插入一行数据”跟“Redis计数加1”这两个操作是分开的，不是原子性的，这就很可能在中间过程因为某些并发出现问题。 更抽象一点：MySQL和Redis是两个不同的载体，将关联数据记录到不同的载体，而不同载体要实现原子性很难，由于不是原子性很容易引起并发问题。如果能将数据统一在同个载体即MySQL，并由其保证操作的原子性，即将插入一行数据和计数加1作为一个完整的事务，通过事务的隔离此时外界看到的就是要么全部执行完毕要么全部都没执行，进而保持逻辑一致。

### 在数据库保存计数

**如果我们把这个计数直接放到数据库里单独的一张计数表 C 中，又会怎么样呢？**

在数据库中建表计数，可以得到精准的计数，方法是通过数据库中的事务来实现的。计数器的修改和数据的写表在一个事务中。读取计数器和查询最近数据也在一个事务中。

### 不同的 count 用法

count() 是一个聚合函数，对于返回的结果集，一行行地判断，如果 count 函数的参数不是 NULL，累计值就加 1，否则不加。最后返回累计值。

`count(*)`、`count(主键 id)` 和 `count(1) `都表示返回满足条件的结果集的总行数；而 `count(字段）`，则表示返回满足条件的数据行里面，参数“字段”不为 NULL 的总个数。

**对于 count(主键 id) 来说，**InnoDB 引擎会遍历整张表，把每一行的 id 值都取出来，返回给 server 层。server 层拿到 id 后，判断是不可能为空的，就按行累加。

**对于 count(1) 来说，**InnoDB 引擎遍历整张表，但不取值。server 层对于返回的每一行，放一个数字“1”进去，判断是不可能为空的，按行累加。

> **count(1) 执行得要比 count(主键 id) 快**。因为从引擎返回 id 会涉及到解析数据行，以及拷贝字段值的操作。

**对于 count(字段) 来说：**

1. 如果这个“字段”是定义为 `not null` 的话，一行行地从记录里面读出这个字段，判断不能为 null，按行累加；
2. 如果这个“字段”定义允许为 `null`，那么执行的时候，判断到有可能是 null，还要把值取出来再判断一下，不是 null 才累加。

> 但是` count(*)`是例外，并不会把全部字段取出来，而是专门做了优化，不取值。count(*) 肯定不是 null，按行累加。
>
> **按照效率排序的话，`count(字段)`<`count(id)`<`count(1)`≈`count(*)`所以我建议你，尽量使用 `count(*)`。**



> 把计数放在 Redis 里面，不能够保证计数和 MySQL 表里的数据精确一致的原因，是这两个不同的存储构成的系统，不支持分布式事务，无法拿到精确一致的视图。而把计数值也放在 MySQL 中，就解决了一致性视图的问题。

## 15 | 答疑文章（一）：日志和索引相关问题

### binlog（归档日志）和 redo log（重做日志）

![image-20230308141416406](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/image-20230308141416406.png)

**在两阶段提交的不同时刻，MySQL 异常重启会出现什么现象。**

如果在图中时刻 A 的地方，也就是写入 redo log 处于 prepare 阶段之后、写 binlog 之前，发生了崩溃（crash），由于此时 binlog 还没写，redo log 也还没提交，所以崩溃恢复的时候，这个事务会回滚。这时候，binlog 还没写，所以也不会传到备库。到这里，大家都可以理解。

大家出现问题的地方，主要集中在时刻 B，也就是 binlog 写完，redo log 还没 commit 前发生 crash，那崩溃恢复的时候 MySQL 会怎么处理？

我们先来看一下崩溃恢复时的判断规则。

1. 如果 redo log 里面的事务是完整的，也就是已经有了 commit 标识，则直接提交；
2. 如果 redo log 里面的事务只有完整的 prepare，则判断对应的事务 binlog 是否存在并完整：
   * a. 如果是，则提交事务；
   * b. 否则，回滚事务。

时刻 B 发生 crash 对应的就是 2(a) 的情况，崩溃恢复过程中事务会被提交

**MySQL 怎么知道 binlog 是完整的?**

一个事务的 binlog 是有完整格式的：

* statement 格式的 binlog，最后会有 COMMIT；
* row 格式的 binlog，最后会有一个 XID event。

> 在 MySQL 5.6.2 版本以后，还引入了 `binlog-checksum` 参数，用来验证 binlog 内容的正确性。对于 binlog 日志由于磁盘原因，可能会在日志中间出错的情况，MySQL 可以通过校验 checksum 的结果来发现。所以，MySQL 还是有办法验证事务 binlog 的完整性的。

**redo log 和 binlog 是怎么关联起来的?**

它们有一个共同的数据字段，叫 XID。崩溃恢复的时候，会按顺序扫描 redo log：

* 如果碰到既有 prepare、又有 commit 的 redo log，就直接提交；
* 如果碰到只有 parepare、而没有 commit 的 redo log，就拿着 XID 去 binlog 找对应的事务。

**处于 prepare 阶段的 redo log 加上完整 binlog，重启就能恢复，MySQL 为什么要这么设计?**

在时刻 B，也就是 binlog 写完以后 MySQL 发生崩溃，这时候 binlog 已经写入了，之后就会被从库（或者用这个 binlog 恢复出来的库）使用。

**如果这样的话，为什么还要两阶段提交呢？干脆先 redo log 写完，再写 binlog。崩溃恢复的时候，必须得两个日志都完整才可以。是不是一样的逻辑？**

对于 InnoDB 引擎来说，如果 redo log 提交完成了，事务就不能回滚（如果这还允许回滚，就可能覆盖掉别的事务的更新）。而如果 redo log 直接提交，然后 binlog 写入的时候失败，InnoDB 又回滚不了，数据和 binlog 日志又不一致了。

> 两阶段提交是经典的分布式系统问题
>
> 其实把Mysql的两阶段提交也可以看成两个分布式服务处理两个不同事情，redo log在Innodb引擎内操作的，binlog是在server层操作的，我们就可以把引擎层和server层看成两个分布式服务，那他们要分别进行两个相关联的操作，就意味着要实现分布式事务，而两阶段提交，就是其中的一种解决方案

**不引入两个日志，也就没有两阶段提交的必要了。只用 binlog 来支持崩溃恢复，又能支持归档，不就可以了？**

如果说历史原因的话，那就是 InnoDB 并不是 MySQL 的原生存储引擎。MySQL 的原生引擎是 MyISAM，设计之初就有没有支持崩溃恢复。

InnoDB 在作为 MySQL 的插件加入 MySQL 引擎家族之前，就已经是一个提供了崩溃恢复和事务支持的引擎了。InnoDB 接入了 MySQL 后，发现既然 binlog 没有崩溃恢复的能力，那就用 InnoDB 原有的 redo log 好了。而如果说实现上的原因的话，就有很多了。

就按照问题中说的，只用 binlog 来实现崩溃恢复的流程，我画了一张示意图，这里就没有 redo log 了。

![image-20230308143324672](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/image-20230308143324672.png)

![image-20230308143344843](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/image-20230308143344843.png)

**那能不能反过来，只用 redo log，不要 binlog？**

![image-20230308143632895](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/image-20230308143632895.png)

**redo log 一般设置多大？**

回答：redo log 太小的话，会导致很快就被写满，然后不得不强行刷 redo log，这样 WAL 机制的能力就发挥不出来了。

所以，如果是现在常见的几个 TB 的磁盘的话，就不要太小气了，直接将 redo log 设置为 4 个文件、每个文件 1GB 吧。

![image-20230308143857593](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/image-20230308143857593.png)

**redo log buffer 是什么？是先修改内存，还是先写 redo log 文件？**

![image-20230308144156236](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/image-20230308144156236.png)

## 16 | “order by”是怎么工作的？

```mysql
CREATE TABLE `t` (
  `id` int(11) NOT NULL,
  `city` varchar(16) NOT NULL,
  `name` varchar(16) NOT NULL,
  `age` int(11) NOT NULL,
  `addr` varchar(128) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `city` (`city`)
) ENGINE=InnoDB;
```

```mysql
select city,name,age from t where city='杭州' order by name limit 1000  ;
```

### 全字段排序

为避免全表扫描，我们需要在 city 字段加上索引。

在 city 字段上创建索引之后，我们用 explain 命令来看看这个语句的执行情况

![img](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/826579b63225def812330ef6c344a303.png)

Extra 这个字段中的“Using filesort”表示的就是需要排序，MySQL 会给每个线程分配一块内存用于排序，称为 sort_buffer。

为了说明这个 SQL 查询语句的执行过程，我们先来看一下 city 这个索引的示意图。

![image-20230308150113957](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/image-20230308150113957.png)

从图中可以看到，满足 city='杭州’条件的行，是从 ID_X 到 ID_(X+N) 的这些记录。

通常情况下，这个语句执行流程如下所示 ：

1. 初始化 sort_buffer，确定放入 name、city、age 这三个字段；
2. 从索引 city 找到第一个满足 city='杭州’条件的主键 id，也就是图中的 ID_X；
3. 到主键 id 索引取出整行，取 name、city、age 三个字段的值，存入 sort_buffer 中；
4. 从索引 city 取下一个记录的主键 id；
5. 重复步骤 3、4 直到 city 的值不满足查询条件为止，对应的主键 id 也就是图中的 ID_Y；
6. 对 sort_buffer 中的数据按照字段 name 做快速排序；
7. 按照排序结果取前 1000 行返回给客户端。

我们暂且把这个排序过程，称为全字段排序，执行流程的示意图如下所示:

![image-20230308151356209](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/image-20230308151356209.png)

图中“按 name 排序”这个动作，可能在内存中完成，也可能需要使用外部排序，这取决于排序所需的内存和参数 sort_buffer_size。

sort_buffer_size，就是 MySQL 为排序开辟的内存（sort_buffer）的大小。如果要排序的数据量小于 sort_buffer_size，排序就在内存中完成。但如果排序数据量太大，内存放不下，则不得不利用磁盘临时文件辅助排序。

> 如果sort buffer的大小足够，那么排序就在内存中完成，采用全字段排序；否则就需要使用磁盘临时文件进行排序，在sort buffer中排好序然后把结果存入临时文件，最后合并成一个大的临时文件，采用归并排序。

```mysql
/* 打开optimizer_trace，只对本线程有效 */
SET optimizer_trace='enabled=on'; 

/* @a保存Innodb_rows_read的初始值 */
select VARIABLE_VALUE into @a from  performance_schema.session_status where variable_name = 'Innodb_rows_read';

/* 执行语句 */
select city, name,age from t where city='杭州' order by name limit 1000; 

/* 查看 OPTIMIZER_TRACE 输出 */
SELECT * FROM `information_schema`.`OPTIMIZER_TRACE`\G

/* @b保存Innodb_rows_read的当前值 */
select VARIABLE_VALUE into @b from performance_schema.session_status where variable_name = 'Innodb_rows_read';

/* 计算Innodb_rows_read差值 */
select @b-@a;
```

这个方法是通过查看 OPTIMIZER_TRACE 的结果来确认的，你可以从 number_of_tmp_files 中看到是否使用了临时文件。

![img](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/89baf99cdeefe90a22370e1d6f5e6495.png)

MySQL 将需要排序的数据分成 12 份，每一份单独排序后存在这些临时文件中。然后把这 12 个有序文件再合并成一个有序的大文件。

如果 sort_buffer_size 超过了需要排序的数据量的大小，number_of_tmp_files 就是 0，表示排序可以直接在内存中完成。否则就需要放在临时文件中排序。

sort_buffer_size 越小，需要分成的份数越多，number_of_tmp_files 的值就越大。

我们的示例表中有 4000 条满足 city='杭州’的记录，所以你可以看到 examined_rows=4000，表示参与排序的行数是 4000 行。

sort_mode 里面的 packed_additional_fields 的意思是，排序过程对字符串做了“紧凑”处理。即使 name 字段的定义是 varchar(16)，在排序过程中还是要按照实际长度来分配空间的。

同时，最后一个查询语句 select @b-@a 的返回结果是 4000，表示整个执行过程只扫描了 4000 行。

这里需要注意的是，为了避免对结论造成干扰，我把 internal_tmp_disk_storage_engine 设置成 MyISAM。否则，select @b-@a 的结果会显示为 4001。

这是因为查询 OPTIMIZER_TRACE 这个表时，需要用到临时表，而 internal_tmp_disk_storage_engine 的默认值是 InnoDB。如果使用的是 InnoDB 引擎的话，把数据从临时表取出来的时候，会让 Innodb_rows_read 的值加 1。

### rowid 排序

在上面这个算法过程里面，只对原表的数据读了一遍，剩下的操作都是在 sort_buffer 和临时文件中执行的。但这个算法有一个问题，就是如果查询要返回的字段很多的话，那么 sort_buffer 里面要放的字段数太多，这样内存里能够同时放下的行数很少，要分成很多个临时文件，排序的性能会很差。

**如果 MySQL 认为排序的单行长度太大会怎么做呢？**

```mysql
SET max_length_for_sort_data = 16;
```

max_length_for_sort_data，是 MySQL 中专门控制用于排序的行数据的长度的一个参数。它的意思是，如果单行的长度超过这个值，MySQL 就认为单行太大，要换一个算法。

city、name、age 这三个字段的定义总长度是 36，我把 max_length_for_sort_data 设置为 16，我们再来看看计算过程有什么改变。

新的算法放入 sort_buffer 的字段，只有要排序的列（即 name 字段）和主键 id。

但这时，排序的结果就因为少了 city 和 age 字段的值，不能直接返回了，整个执行流程就变成如下所示的样子：

1. 初始化 sort_buffer，确定放入两个字段，即 name 和 id；
2. 从索引 city 找到第一个满足 city='杭州’条件的主键 id，也就是图中的 ID_X；
3. 到主键 id 索引取出整行，取 name、id 这两个字段，存入 sort_buffer 中；
4. 从索引 city 取下一个记录的主键 id；
5. 重复步骤 3、4 直到不满足 city='杭州’条件为止，也就是图中的 ID_Y；
6. 对 sort_buffer 中的数据按照字段 name 进行排序；
7. 遍历排序结果，取前 1000 行，并按照 id 的值回到原表中取出 city、name 和 age 三个字段返回给客户端。

这个执行流程的示意图如下，我把它称为 rowid 排序。

![image-20230308153211272](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/image-20230308153211272.png)

需要说明的是，最后的“结果集”是一个逻辑概念，实际上 MySQL 服务端从排序后的 sort_buffer 中依次取出 id，然后到原表查到 city、name 和 age 这三个字段的结果，不需要在服务端再耗费内存存储结果，是直接返回给客户端的。

根据这个说明过程和图示，你可以想一下，这个时候执行 select @b-@a，结果会是多少呢？

现在，我们就来看看结果有什么不同。首先，图中的 examined_rows 的值还是 4000，表示用于排序的数据是 4000 行。但是 select @b-@a 这个语句的值变成 5000 了。

因为这时候除了排序过程外，在排序完成后，还要根据 id 去原表取值。由于语句是 limit 1000，因此会多读 1000 行。

![image-20230308153604308](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/image-20230308153604308.png)

从 OPTIMIZER_TRACE 的结果中，你还能看到另外两个信息也变了。

* sort_mode 变成了 ，表示参与排序的只有 name 和 id 这两个字段。
* number_of_tmp_files 变成 10 了，是因为这时候参与排序的行数虽然仍然是 4000 行，但是每一行都变小了，因此需要排序的总数据量就变小了，需要的临时文件也相应地变少了。

### 全字段排序 VS rowid 排序

如果 MySQL 实在是担心排序内存太小，会影响排序效率，才会采用 rowid 排序算法，这样排序过程中一次可以排序更多行，但是需要再回到原表去取数据。

如果 MySQL 认为内存足够大，会优先选择全字段排序，把需要的字段都放到 sort_buffer 中，这样排序后就会直接从内存里面返回查询结果了，不用再回到原表去取数据。

> **如果内存够，就要多利用内存，尽量减少磁盘访问。**

并不是所有的 order by 语句，都需要排序操作的。从上面分析的执行过程，我们可以看到，MySQL 之所以需要生成临时表，并且在临时表上做排序操作，其原因是原来的数据都是无序的

> 要排序的字段包含在索引中，那么天然有序，数据库就不会再排序，而是直接将结果返回。

覆盖索引是指，索引上的信息足够满足查询请求，不需要再回到主键索引上去取数据。

**对于 InnoDB 表来说，执行全字段排序会减少磁盘访问，因此会被优先选择。**

## 17 | 如何正确地显示随机消息？

表中有10000行数据

### 内存临时表

```mysql
mysql> select word from words order by rand() limit 3;
```

![img](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/59a4fb0165b7ce1184e41f2d061ce350.png)

Extra 字段显示 Using temporary，表示的是需要使用临时表；Using filesort，表示的是需要执行排序操作。

**对于内存表，回表过程只是简单地根据数据行的位置，直接访问内存得到数据，根本不会导致多访问磁盘。**优化器没有了这一层顾虑，那么它会优先考虑的，就是用于排序的行越小越好了，所以，MySQL 这时就会选择 rowid 排序。

执行流程：

1. 创建一个临时表。这个临时表使用的是 memory 引擎，表里有两个字段，第一个字段是 double 类型，为了后面描述方便，记为字段 R，第二个字段是 varchar(64) 类型，记为字段 W。并且，这个表没有建索引。
2. 从 words 表中，按主键顺序取出所有的 word 值。对于每一个 word 值，调用 rand() 函数生成一个大于 0 小于 1 的随机小数，并把这个随机小数和 word 分别存入临时表的 R 和 W 字段中，到此，扫描行数是 10000。
3. 现在临时表有 10000 行数据了，接下来你要在这个没有索引的内存临时表上，按照字段 R 排序。
4. 初始化 sort_buffer。sort_buffer 中有两个字段，一个是 double 类型，另一个是整型。
5. 从内存临时表中一行一行地取出 R 值和位置信息（我后面会和你解释这里为什么是“位置信息”），分别存入 sort_buffer 中的两个字段里。这个过程要对内存临时表做全表扫描，此时扫描行数增加 10000，变成了 20000。
6. 在 sort_buffer 中根据 R 的值进行排序。注意，这个过程没有涉及到表操作，所以不会增加扫描行数。
7. 排序完成后，取出前三个结果的位置信息，依次到内存临时表中取出 word 值，返回给客户端。这个过程中，访问了表的三行数据，总扫描行数变成了 20003。

![image-20230313153033554](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/202303131530652.png)

如果把一个 InnoDB 表的主键删掉，是不是就没有主键，就没办法回表了？

如果你创建的表没有主键，或者把一个表的主键删掉了，那么 InnoDB 会自己生成一个长度为 6 字节的 rowid 来作为主键。

* 对于有主键的 InnoDB 表来说，这个 rowid 就是主键 ID；
* 对于没有主键的 InnoDB 表来说，这个 rowid 就是由系统生成的；
* MEMORY 引擎不是索引组织表。在这个例子里面，你可以认为它就是一个数组。因此，这个 rowid 其实就是数组的下标。

> order by rand() 使用了内存临时表，内存临时表排序的时候使用了 rowid 排序方法。

### 磁盘临时表

是不是所有的临时表都是内存表呢？

其实不是的。tmp_table_size 这个配置限制了内存临时表的大小，默认值是 16M。如果临时表大小超过了 tmp_table_size，那么内存临时表就会转成磁盘临时表。

### 随机排序方法

如果只随机选择 1 个 word 值，可以怎么做呢？思路上是这样的：

1. 取得这个表的主键 id 的最大值 M 和最小值 N;
2. 用随机函数生成一个最大值到最小值之间的数 X = (M-N)*rand() + N;
3. 取不小于 X 的第一个 ID 的行。

```mysql
mysql> select max(id),min(id) into @M,@N from t ;
set @X= floor((@M-@N+1)*rand() + @N);
select * from t where id >= @X limit 1;
```

这个方法效率很高，因为取 max(id) 和 min(id) 都是不需要扫描索引的，而第三步的 select 也可以用索引快速定位，可以认为就只扫描了 3 行。但实际上，这个算法本身并不严格满足题目的随机要求，因为 ID 中间可能有空洞，因此选择不同行的概率不一样，不是真正的随机。

比如你有 4 个 id，分别是 1、2、4、5，如果按照上面的方法，那么取到 id=4 的这一行的概率是取得其他行概率的两倍。

如果这四行的 id 分别是 1、2、40000、40001 呢？这个算法基本就能当 bug 来看待了。所以，为了得到严格随机的结果，你可以用下面这个流程:

* 取得整个表的行数，并记为 C。
* 取得 Y = floor(C * rand())。 floor 函数在这里的作用，就是取整数部分。
* 再用 limit Y,1 取得一行。

```mysql
mysql> select count(*) into @C from t;
set @Y = floor(@C * rand());
set @sql = concat("select * from t limit ", @Y, ",1");
prepare stmt from @sql;
execute stmt;
DEALLOCATE prepare stmt;
```

由于 limit 后面的参数不能直接跟变量，所以我在上面的代码中使用了 prepare+execute 的方法。你也可以把拼接 SQL 语句的方法写在应用程序中，会更简单些。

要随机取 3 个 word 值呢？你可以这么做：

* 取得整个表的行数，记为 C；
* 根据相同的随机方法得到 Y1、Y2、Y3；
* 再执行三个 limit Y, 1 语句得到三行数据。我们把这个算法，称作随机算法

```mysql
mysql> select count(*) into @C from t;
set @Y1 = floor(@C * rand());
set @Y2 = floor(@C * rand());
set @Y3 = floor(@C * rand());
select * from t limit @Y1，1； //在应用代码里面取Y1、Y2、Y3值，拼出SQL后执行
select * from t limit @Y2，1；
select * from t limit @Y3，1；
```

### order by 存在两种排序方式。

通过max_length_for_sort_data（行最大长度配置）来决定是使用全字段排序，还是rowId排序。

对于这两种排序优先级来说，全字段排序优先级最高。通常InnoDB认为，rowid排序会要求回表多造成磁盘读，因此不会被优先选择（数据存储在磁盘上，回表通常要去磁盘加载数据到Buffer Pool）。

#### 全字段排序

在max_length_for_sort_data（排序数据一行最大长度）足够时，会采用全字段排序的方式。

1. 初始化Sort Buffer 字段（查询全部字段）
2. 确认使用的索引，并将通过索引获取数据可能需要回表查询全部数据。
3. 将全部数据 存入sort buffer
4. 基于排序字段排序
5. 返回排序结果

#### rowId 排序

在max_length_for_sort_data（排序数据一行最大长度）不足时，会使用rowId排序方式。

1. 初始化sort buffer字段 （排序字段+id）
2. 确认使用的索引，然后回表查询排序字段，
3. 将字段放入 sort buffer中
4. 执行排序
5. 回表查询结果数据（返回全字段）
6. 返回结果

### 优先队列排序算法

优先队列排序算法可以理解为，假如有10000条数据为只需要最大的10条。那么，此时我是否需要保证10000条数据都有序呢？

其实从效率上来讲，肯定是没有必要的。因为只需要10条，那么我就只用保证10条有序就OK。方式就是，创建一个队列，将10条数据放进队列中，后续数据一次进行比较，如果大于其中任何一条，替换该位置数据即可。这样排序效率远大于归并排序。

因此InnoDB在情况允许时会使用优先队列排序算法。

思考：如果此时需要返回1000条，那么还会用到有限队列排序么？

解答：从逻辑上来讲，优先队列排序效率也不是一定高于归并排序的。比如一共100条数据，我要取最大99条，那么需要一个 99 条数据的队列，然后 最后一条数据要依次比对 100 次， 然后 再对 队列中 99 条数据 做排序。排序次数都一致。
 而且，由于队列原因，占用内存也比较高。因此，除了数量外，还需要考虑内存占用情况。如果超过 sort buffer 大小那么也不会采用优先队列算法。

```mysql
select city,name,age from t where city='杭州' order by name limit 1000  ;
```

这里也用到了 limit，为什么没用优先队列排序算法呢？原因是，这条 SQL 语句是 limit 1000，如果使用优先队列算法的话，需要维护的堆的大小就是 1000 行的 (name,rowid)，超过了我设置的 sort_buffer_size 大小，所以只能使用归并排序算法。

**select * from t where city in (“杭州”," 苏州 ") order by name limit 100; 这个 SQL 语句是否需要排序？**

虽然有 (city,name) 联合索引，对于单个 city 内部，name 是递增的。但是由于这条 SQL 语句不是要单独地查一个 city 的值，而是同时查了"杭州"和" 苏州 "两个城市，因此所有满足条件的 name 就不是递增的了。也就是说，这条 SQL 语句需要排序。

需要排序：

1. 执行 `select * from t where city=“杭州” order by name limit 100;` 这个语句是不需要排序的，客户端用一个长度为 100 的内存数组 A 保存结果。
2. 执行 `select * from t where city=“苏州” order by name limit 100; `用相同的方法，假设结果被存进了内存数组 B。
3. 现在 A 和 B 是两个有序数组，然后你可以用归并排序的思想，得到 name 最小的前 100 值，就是我们需要的结果了。

## 18 | 为什么这些SQL语句逻辑相同，性能却差异巨大？

### 案例一：条件字段函数操作

假设你现在维护了一个交易系统，其中交易记录表 tradelog 包含交易流水号（tradeid）、交易员 id（operator）、交易时间（t_modified）等字段。为了便于描述，我们先忽略其他字段。这个表的建表语句如下：

```mysql
mysql> CREATE TABLE `tradelog` (
  `id` int(11) NOT NULL,
  `tradeid` varchar(32) DEFAULT NULL,
  `operator` int(11) DEFAULT NULL,
  `t_modified` datetime DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `tradeid` (`tradeid`),
  KEY `t_modified` (`t_modified`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
```

假设，现在已经记录了从 2016 年初到 2018 年底的所有数据，运营部门有一个需求是，要统计发生在所有年份中 7 月份的交易记录总数。这个逻辑看上去并不复杂，你的 SQL 语句可能会这么写：

```mysql
mysql> select count(*) from tradelog where month(t_modified)=7;
```

由于 t_modified 字段上有索引，于是你就很放心地在生产库中执行了这条语句，但却发现执行了特别久，才返回了结果。

**如果对字段做了函数计算，就用不上索引了，这是 MySQL 的规定。**

为什么条件是 where t_modified='2018-7-1’的时候可以用上索引，而改成 where month(t_modified)=7 的时候就不行了？

下面是这个 t_modified 索引的示意图。方框上面的数字就是 month() 函数对应的值

![image-20230313163022426](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/202303131630513.png)

如果你的 SQL 语句条件用的是 where t_modified='2018-7-1’的话，引擎就会按照上面绿色箭头的路线，快速定位到 t_modified='2018-7-1’需要的结果。

**实际上，B+ 树提供的这个快速定位能力，来源于同一层兄弟节点的有序性。**

但是，如果计算 month() 函数的话，你会看到传入 7 的时候，在树的第一层就不知道该怎么办了。

> **对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。**

### 案例二：隐式类型转换

```mysql
mysql> select * from tradelog where tradeid=110717;
```

tradeid 的字段类型是 varchar(32)，而输入的参数却是整型，所以需要做类型转换。

select “10” > 9 的结果：

* 如果规则是“将字符串转成数字”，那么就是做数字比较，结果应该是 1；
* 如果规则是“将数字转成字符串”，那么就是做字符串比较，结果应该是 0。

![image-20230313171447361](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/202303131714424.png)

从图中可知，select “10” > 9 返回的是 1，所以你就能确认 MySQL 里的转换规则了：在 MySQL 中，**字符串和数字做比较的话，是将字符串转换成数字。**

这时，你再看这个全表扫描的语句：

```mysql
mysql> select * from tradelog where tradeid=110717;
```

就知道对于优化器来说，这个语句相当于：

```mysql
mysql> select * from tradelog where  CAST(tradid AS signed int) = 110717;
```

现在，我留给你一个小问题，id 的类型是 int，如果执行下面这个语句，是否会导致全表扫描呢？(不会)

```mysql
select * from tradelog where id="83126";
```

### 案例三：隐式字符编码转换

假设系统里还有另外一个表 trade_detail，用于记录交易的操作细节。为了便于量化分析和复现，我往交易日志表 tradelog 和交易详情表 trade_detail 这两个表里插入一些数据。

```mysql
mysql> CREATE TABLE `trade_detail` (
  `id` int(11) NOT NULL,
  `tradeid` varchar(32) DEFAULT NULL,
  `trade_step` int(11) DEFAULT NULL, /*操作步骤*/
  `step_info` varchar(32) DEFAULT NULL, /*步骤信息*/
  PRIMARY KEY (`id`),
  KEY `tradeid` (`tradeid`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

insert into tradelog values(1, 'aaaaaaaa', 1000, now());
insert into tradelog values(2, 'aaaaaaab', 1000, now());
insert into tradelog values(3, 'aaaaaaac', 1000, now());

insert into trade_detail values(1, 'aaaaaaaa', 1, 'add');
insert into trade_detail values(2, 'aaaaaaaa', 2, 'update');
insert into trade_detail values(3, 'aaaaaaaa', 3, 'commit');
insert into trade_detail values(4, 'aaaaaaab', 1, 'add');
insert into trade_detail values(5, 'aaaaaaab', 2, 'update');
insert into trade_detail values(6, 'aaaaaaab', 3, 'update again');
insert into trade_detail values(7, 'aaaaaaab', 4, 'commit');
insert into trade_detail values(8, 'aaaaaaac', 1, 'add');
insert into trade_detail values(9, 'aaaaaaac', 2, 'update');
insert into trade_detail values(10, 'aaaaaaac', 3, 'update again');
insert into trade_detail values(11, 'aaaaaaac', 4, 'commit');
```

这时候，如果要查询 id=2 的交易的所有操作步骤信息，SQL 语句可以这么写：

```mysql
mysql> select d.* from tradelog l, trade_detail d where d.tradeid=l.tradeid and l.id=2; /*语句Q1*/
```

![img](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/202303131722232.png)

1. 第一行显示优化器会先在交易记录表 tradelog 上查到 id=2 的行，这个步骤用上了主键索引，rows=1 表示只扫描一行；
2. 第二行 key=NULL，表示没有用上交易详情表 trade_detail 上的 tradeid 索引，进行了全表扫描。

![image-20230313172829871](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/202303131728977.png)

## 19 | 为什么我只查一行的语句，也执行这么慢？

这个表有两个字段 id 和 c，并且我在里面插入了 10 万行记录。

```mysql
mysql> CREATE TABLE `t` (
  `id` int(11) NOT NULL,
  `c` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB;

delimiter ;;
create procedure idata()
begin
  declare i int;
  set i=1;
  while(i<=100000) do
    insert into t values(i,i);
    set i=i+1;
  end while;
end;;
delimiter ;

call idata();
```

### 第一类：查询长时间不返回

```mysql
mysql> select * from t where id=1;
```

![image-20230313210921775](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/202303132109846.png)

一般碰到这种情况的话，大概率是表 t 被锁住了。接下来分析原因的时候，一般都是首先执行一下 show processlist 命令，看看当前语句处于什么状态。

> `SHOW PROCESSLIST`显示哪些线程正在运行。 show processlist;只列出前100条，如果想全列出请使用show full processlist; 用途：执行show processlist命令可以看到该条语句的执行状态，比如可以看死锁情况

等 MDL 锁

![image-20230313211209720](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/202303132112842.png)

等 flush

等行锁

### 第二类：查询慢

```mysql
mysql> select * from t where c=50000 limit 1;
```

作为确认，你可以看一下慢查询日志。注意，这里为了把所有语句记录到 slow log 里，我在连接后先执行了 set long_query_time=0，将慢查询日志的时间阈值设置为 0。

![image-20230313213554188](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/202303132135259.png)

Rows_examined 显示扫描了 50000 行。你可能会说，不是很慢呀，11.5 毫秒就返回了，我们线上一般都配置超过 1 秒才算慢查询。但你要记住：**坏查询不一定是慢查询**。我们这个例子里面只有 10 万行记录，数据量大起来的话，执行时间就线性涨上去了。

## 20 | 幻读是什么，幻读有什么问题？

```mysql
CREATE TABLE `t` (
  `id` int(11) NOT NULL,
  `c` int(11) DEFAULT NULL,
  `d` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `c` (`c`)
) ENGINE=InnoDB;

insert into t values(0,0,0),(5,5,5),
(10,10,10),(15,15,15),(20,20,20),(25,25,25);
```

这个表除了主键 id 外，还有一个索引 c，初始化语句在表中插入了 6 行数据。

```mysql
begin;
select * from t where d=5 for update;
commit;
```

> select for update 是为了在查询时,对这条数据进行加锁,避免其他用户以该表进行插入,修改或删除等操作,造成表的不一致性.
>
> **select for update 加写锁。事物提交才释放**

比较好理解的是，这个语句会命中 d=5 的这一行，对应的主键 id=5，因此在 select 语句执行完成后，id=5 这一行会加一个写锁，而且由于两阶段锁协议，这个写锁会在执行 commit 语句的时候释放。

由于字段 d 上没有索引，因此这条查询语句会做全表扫描。那么，其他被扫描到的，但是不满足条件的 5 行记录上，会不会被加锁呢？

> RR级别：扫描到的数据都会加行锁和间隙锁 RC级别：扫描到的数据都会加行锁，但是不满足条件的数据，没有到commit阶段，就会释放，违反了两阶段加锁原则 全表扫描一直指的是扫描主键索引

**InnoDB 的默认事务隔离级别是可重复读**

### 幻读是什么？

如果只在 id=5 这一行加锁，而其他行的不加锁的话，会怎么样。

![image-20230314142751696](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/202303141427830.png)

可以看到，session A 里执行了三次查询，分别是 Q1、Q2 和 Q3。它们的 SQL 语句相同，都是 select * from t where d=5 for update。这个语句的意思你应该很清楚了，查所有 d=5 的行，而且使用的是当前读，并且加上写锁。现在，我们来看一下这三条 SQL 语句，分别会返回什么结果。

1. Q1 只返回 id=5 这一行；
2. 在 T2 时刻，session B 把 id=0 这一行的 d 值改成了 5，因此 T3 时刻 Q2 查出来的是 id=0 和 id=5 这两行；
3. 在 T4 时刻，session C 又插入一行（1,1,5），因此 T5 时刻 Q3 查出来的是 id=0、id=1 和 id=5 的这三行。

其中，Q3 读到 id=1 这一行的现象，被称为“幻读”。也就是说**，幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。**

那这里update导致的结果不属于幻读，而是不可重复读。不可重复读指修改行记录值。幻读是指新增

幻读只针对新增的记录，查询时记录条数不一样

> 1. 在可重复读隔离级别下，普通的查询是快照读，是不会看到别的事务插入的数据的。因此，幻读在“当前读”下才会出现。
> 2. 上面 session B 的修改结果，被 session A 之后的 select 语句用“当前读”看到，不能称为幻读。**幻读仅专指“新插入的行”。**
>
> 注意区分快照读和当前读。
>
> *  **当前读**指的是select for update或者select in share mode，指的是在更新之前必须先查寻当前的值，因此叫当前读。
> *  **快照读**指的是在语句执行之前或者在事务开始的时候会创建一个视图，后面的读都是基于这个视图的，不会再去查询最新的值。

因为这三个查询都是加了 for update，都是当前读。而当前读的规则，就是要能读到所有已经提交的记录的最新值。并且，session B 和 sessionC 的两条语句，执行后就会提交，所以 Q2 和 Q3 就是应该看到这两个事务的操作效果，而且也看到了，这跟事务的可见性规则并不矛盾。

### 幻读有什么问题？

首先是语义上的。session A 在 T1 时刻就声明了，“我要把所有 d=5 的行锁住，不准别的事务进行读写操作”。而实际上，这个语义被破坏了。

![image-20230314145858380](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/202303141458494.png)

session B 的第二条语句 update t set c=5 where id=0，语义是“我把 id=0、d=5 这一行的 c 值，改成了 5”。

由于在 T1 时刻，session A 还只是给 id=5 这一行加了行锁， 并没有给 id=0 这行加上锁。因此，session B 在 T2 时刻，是可以执行这两条 update 语句的。这样，就破坏了 session A 里 Q1 语句要锁住所有 d=5 的行的加锁声明。

session C 也是一样的道理，对 id=1 这一行的修改，也是破坏了 Q1 的加锁声明。

**其次，是数据一致性的问题。**

我们知道，锁的设计是为了保证数据的一致性。而这个一致性，**不止是数据库内部数据状态在此刻的一致性，还包含了数据和日志在逻辑上的一致性。**

![image-20230314150305856](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/202303141503978.png)

update 的加锁语义和 select …for update 是一致的，所以这时候加上这条 update 语句也很合理。session A 声明说“要给 d=5 的语句加上锁”，就是为了要更新数据，新加的这条 update 语句就是把它认为加上了锁的这一行的 d 值修改成了 100。

现在，我们来分析一下图 3 执行完成后，数据库里会是什么结果。

1. 经过 T1 时刻，id=5 这一行变成 (5,5,100)，当然这个结果最终是在 T6 时刻正式提交的 ;
2. 经过 T2 时刻，id=0 这一行变成 (0,5,5);
3. 经过 T4 时刻，表里面多了一行 (1,5,5);
4. 其他行跟这个执行序列无关，保持不变。

这样看，这些数据也没啥问题，但是我们再来看看这时候 binlog 里面的内容。

1. T2 时刻，session B 事务提交，写入了两条语句；
2. T4 时刻，session C 事务提交，写入了两条语句；
3. T6 时刻，session A 事务提交，写入了 update t set d=100 where d=5 

这条语句。我统一放到一起的话，就是这样的：

```mysql
update t set d=5 where id=0; /*(0,0,5)*/
update t set c=5 where id=0; /*(0,5,5)*/

insert into t values(1,1,5); /*(1,1,5)*/
update t set c=5 where id=1; /*(1,5,5)*/

update t set d=100 where d=5;/*所有d=5的行，d改成100*/
```

好，你应该看出问题了。这个语句序列，不论是拿到备库去执行，还是以后用 binlog 来克隆一个库，这三行的结果，都变成了 (0,5,100)、(1,5,100) 和 (5,5,100)。

也就是说，id=0 和 id=1 这两行，发生了数据不一致。这个问题很严重，是不行的。

到这里，我们再回顾一下，这个数据不一致到底是怎么引入的？

我们分析一下可以知道，这是我们假设“select * from t where d=5 for update 这条语句只给 d=5 这一行，也就是 id=5 的这一行加锁”导致的。所以我们认为，上面的设定不合理，要改。那怎么改呢？我们把扫描过程中碰到的行，也都加上写锁，再来看看执行效果。

![image-20230314152239232](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/202303141522324.png)

由于 session A 把所有的行都加了写锁，所以 session B 在执行第一个 update 语句的时候就被锁住了。需要等到 T6 时刻 session A 提交以后，session B 才能继续执行。

这样对于 id=0 这一行，在数据库里的最终结果还是 (0,5,5)。在 binlog 里面，执行序列是这样的：

```mysql
insert into t values(1,1,5); /*(1,1,5)*/
update t set c=5 where id=1; /*(1,5,5)*/

update t set d=100 where d=5;/*所有d=5的行，d改成100*/

update t set d=5 where id=0; /*(0,0,5)*/
update t set c=5 where id=0; /*(0,5,5)*/
```

可以看到，按照日志顺序执行，id=0 这一行的最终结果也是 (0,5,5)。所以，id=0 这一行的问题解决了。

但同时你也可以看到，id=1 这一行，在数据库里面的结果是 (1,5,5)，而根据 binlog 的执行结果是 (1,5,100)，也就是说幻读的问题还是没有解决。为什么我们已经这么“凶残”地，把所有的记录都上了锁，还是阻止不了 id=1 这一行的插入和更新呢？

在 T3 时刻，我们给所有行加锁的时候，id=1 这一行还不存在，不存在也就加不上锁。

> 幻读产生的原因：即使给所有行加上了锁，也避免不了幻读，这是因为给行加锁的时候，这条记录还不存在，没法加锁

也就是说，即使把**所有的记录都加上锁，还是阻止不了新插入的记录**

> 幻读问题是：没插入的行没法就加行锁，因此限制不了，会产生语义和一致性(binlog 顺序)问题。 定义：读到了新插入的数据。 问题解决：**引入间隙锁（GAP）**

### 如何解决幻读？

现在你知道了，产生幻读的原因是，行锁只能锁住行，但是新插入记录这个动作，要更新的是记录之间的“间隙”。因此，**为了解决幻读问题，InnoDB 只好引入新的锁，也就是间隙锁 (Gap Lock)。**

顾名思义，**间隙锁，锁的就是两个值之间的空隙。**比如文章开头的表 t，初始化插入了 6 个记录，这就产生了 7 个间隙。

![image-20230314162941997](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/202303141629095.png)

当你执行 select * from t where d=5 for update 的时候，就不止是给数据库中已有的 6 个记录加上了行锁，还同时加了 7 个间隙锁。这样就确保了无法再插入新的记录。

**在一行行扫描的过程中，不仅将给行加上了行锁，还给行两边的空隙，也加上了间隙锁。**

> 1.对主键或唯一索引，如果当前读时，where条件全部精确命中(=或者in)，这种场景本身就不会出现幻读，所以只会加行记录锁。 　　2.没有索引的列，当前读操作时，会加全表gap锁，生产环境要注意。 　　3.非唯一索引列，如果where条件部分命中(>、<、like等)或者全未命中，则会加附近Gap间隙锁。例如，某表数据如下，非唯一索引2,6,9,9,11,15。如下语句要操作非唯一索引列9的数据，gap锁将会锁定的列是(6,11]，该区间内无法插入数据。

行锁，分成读锁和写锁

![image-20230315135232939](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/202303151352896.png)

跟行锁有冲突关系的是“另外一个行锁”。

**跟间隙锁存在冲突关系的，是“往这个间隙中插入一个记录”这个操作**。间隙锁之间都不存在冲突关系。

**共享锁 (lock in share mode)**

允许不同事务之间加**共享锁**(`lock in share mode`)读取，但不允许其它事务修改或者加入排他锁(`for update`)
如果有修改必须等待一个事务提交完成，才可以执行，容易出现死锁

![image-20230315135931889](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/202303151359071.png)

这里 session B 并不会被堵住。因为表 t 里并没有 c=7 这个记录，因此 session A 加的是间隙锁 (5,10)。而 session B 也是在这个间隙加的间隙锁。它们有共同的目标，即：保护这个间隙，不允许插入值。但，它们之间是不冲突的。

间隙锁和行锁合称 next-key lock，每个 next-key lock 是**前开后闭区间**。也就是说，我们的表 t 初始化以后，如果用 select * from t for update 要把整个表所有记录锁起来，就形成了 7 个 next-key lock，分别是 (-∞,0]、(0,5]、(5,10]、(10,15]、(15,20]、(20, 25]、(25, +supremum]。

> InnoDB 给每个索引加了一个不存在的最大值 supremum

这种行不存在的情况，无法加行锁，只能加间隙锁，而间隙锁相互间不冲突，这样就及其容易死锁。

![image-20230315140920062](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/202303151409232.png)

按语句执行顺序来分析一下：

1. session A 执行 select … for update 语句，由于 id=9 这一行并不存在，因此会加上间隙锁 (5,10);
2. session B 执行 select … for update 语句，同样会加上间隙锁 (5,10)，间隙锁之间不会冲突，因此这个语句可以执行成功；
3. session B 试图插入一行 (9,9,9)，被 session A 的间隙锁挡住了，只好进入等待；
4. session A 试图插入一行 (9,9,9)，被 session B 的间隙锁挡住了。

两个 session 进入互相等待状态，形成死锁。当然，InnoDB 的死锁检测马上就发现了这对死锁关系，让 session A 的 insert 语句报错返回了。

**间隙锁的引入，可能会导致同样的语句锁住更大的范围，这其实是影响了并发度的。**

> **间隙锁是在可重复读隔离级别下才会生效的。**所以，你如果把隔离级别设置为读提交的话，就没有间隙锁了。 但同时，你要解决可能出现的数据和日志不一致问题，需要把 binlog 格式设置为 row。这，也是现在不少公司使用的配置组合。

## 21 | 为什么我只改一行的语句，锁这么多？

加锁规则里面，包含了两个“原则”、两个“优化”和一个“bug”。

1. 原则 1：加锁的基本单位是 next-key lock。希望你还记得，next-key lock 是前开后闭区间。
2. 原则 2：查找过程中访问到的对象才会加锁。
3. 优化 1：索引上的等值查询，给唯一索引加锁的时候，next-key lock 退化为行锁。
4. 优化 2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock 退化为间隙锁。
5. 一个 bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。

```mysql
CREATE TABLE `t` (
  `id` int(11) NOT NULL,
  `c` int(11) DEFAULT NULL,
  `d` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `c` (`c`)
) ENGINE=InnoDB;

insert into t values(0,0,0),(5,5,5),(10,10,10),(15,15,15),(20,20,20),(25,25,25);
```

### 案例一：等值查询间隙锁

![image-20230315143622934](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/202303151436110.png)

由于表 t 中没有 id=7 的记录，所以用我们上面提到的加锁规则判断一下的话：

1. 根据原则 1，加锁单位是 next-key lock，session A 加锁范围就是 (5,10]；
2. 同时根据优化 2，这是一个等值查询 (id=7)，而 id=10 不满足查询条件，next-key lock 退化成间隙锁，因此最终加锁的范围是 (5,10)。

所以，session B 要往这个间隙里面插入 id=8 的记录会被锁住，但是 session C 修改 id=10 这行是可以的。

### 案例二：非唯一索引等值锁

![image-20230315144314795](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/202303151443989.png)

这里 session A 要给索引 c 上 c=5 的这一行加上读锁。

1. 根据原则 1，加锁单位是 next-key lock，因此会给 (0,5]加上 next-key lock。要注意 c 是普通索引，因此仅访问 c=5 这一条记录是不能马上停下来的，需要向右遍历，查到 c=10 才放弃。
2. 根据原则 2，访问到的都要加锁，因此要给 (5,10]加 next-key lock。
3. 但是同时这个符合优化 2：等值判断，向右遍历，最后一个值不满足 c=5 这个等值条件，因此退化成间隙锁 (5,10)。
4. 根据原则 2 ，只有访问到的对象才会加锁，这个查询使用覆盖索引，并不需要访问主键索引，所以主键索引上没有加任何锁，这就是为什么 session B 的 update 语句可以执行完成。

lock in share mode 只锁覆盖索引，但是如果是 for update 就不一样了。 执行 for update 时，系统会认为你接下来要更新数据，因此会顺便给主键索引上满足条件的行加上行锁。

### 案例三：主键索引范围锁

```mysql
mysql> select * from t where id=10 for update;
mysql> select * from t where id>=10 and id<11 for update;
```

你可能会想，id 定义为 int 类型，这两个语句就是等价的吧？其实，它们并不完全等价。

![image-20230315151113691](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/202303151511928.png)

1. 开始执行的时候，要找到第一个 id=10 的行，因此本该是 next-key lock(5,10]。 根据优化 1， 主键 id 上的等值条件，退化成行锁，只加了 id=10 这一行的行锁。
2. 范围查找就往后继续找，找到 id=15 这一行停下来，因此需要加 next-key lock(10,15]。

所以，session A 这时候锁的范围就是主键索引上，行锁 id=10 和 next-key lock(10,15]。这样，session B 和 session C 的结果你就能理解了。

### 案例四：非唯一索引范围锁

![image-20230315151654795](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/202303151516033.png)

这次 session A 用字段 c 来判断，加锁规则跟案例三唯一的不同是：在第一次用 c=10 定位记录的时候，索引 c 上加了 (5,10]这个 next-key lock 后，由于索引 c 是非唯一索引，没有优化规则，也就是说不会蜕变为行锁，因此最终 sesion A 加的锁是，索引 c 上的 (5,10] 和 (10,15] 这两个 next-key lock。

### 案例五：唯一索引范围锁 bug

![image-20230315152106016](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/202303151521199.png)

session A 是一个范围查询，按照原则 1 的话，应该是索引 id 上只加 (10,15]这个 next-key lock，并且因为 id 是唯一键，所以循环判断到 id=15 这一行就应该停止了。

但是实现上，InnoDB 会往前扫描到第一个不满足条件的行为止，也就是 id=20。而且由于这是个范围扫描，因此索引 id 上的 (15,20]这个 next-key lock 也会被锁上。

所以你看到了，session B 要更新 id=20 这一行，是会被锁住的。同样地，session C 要插入 id=16 的一行，也会被锁住。

### 案例六：非唯一索引上存在"等值"的例子

```mysql
mysql> insert into t values(30,10,30);
```

新插入的这一行 c=10，也就是说现在表里有两个 c=10 的行。那么，这时候索引 c 上的间隙是什么状态了呢？你要知道，由于非唯一索引上包含主键的值，所以是不可能存在“相同”的两行的。

![image-20230315152530648](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/202303151525883.png)

可以看到，虽然有两个 c=10，但是它们的主键值 id 是不同的（分别是 10 和 30），因此这两个 c=10 的记录之间，也是有间隙的。

图中我画出了索引 c 上的主键 id。为了跟间隙锁的开区间形式进行区别，我用 (c=10,id=30) 这样的形式，来表示索引上的一行。

这次我们用 delete 语句来验证。注意，delete 语句加锁的逻辑，其实跟 select ... for update 是类似的，也就是我在文章开始总结的两个“原则”、两个“优化”和一个“bug”。

![image-20230315152908265](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/202303151529499.png)

这时，session A 在遍历的时候，先访问第一个 c=10 的记录。同样地，根据原则 1，这里加的是 (c=5,id=5) 到 (c=10,id=10) 这个 next-key lock。

然后，session A 向右查找，直到碰到 (c=15,id=15) 这一行，循环才结束。根据优化 2，这是一个等值查询，向右查找到了不满足条件的行，所以会退化成 (c=10,id=10) 到 (c=15,id=15) 的间隙锁。

也就是说，这个 delete 语句在索引 c 上的加锁范围，就是下图中蓝色区域覆盖的部分。

![image-20230315153049841](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/202303151530038.png)

这个蓝色区域左右两边都是虚线，表示开区间，即 (c=5,id=5) 和 (c=15,id=15) 这两行上都没有锁。

### 案例七：limit 语句加锁

![image-20230315153255667](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/202303151532867.png)

这个例子里，session A 的 delete 语句加了 limit 2。你知道表 t 里 c=10 的记录其实只有两条，因此加不加 limit 2，删除的效果都是一样的，但是加锁的效果却不同。可以看到，session B 的 insert 语句执行通过了，跟案例六的结果不同。

因此，索引 c 上的加锁范围就变成了从（c=5,id=5) 到（c=10,id=30) 这个前开后闭区间，如下图所示：

![image-20230315153520951](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/202303151535160.png)

> 在**删除数据的时候尽量加 limit**。这样不仅可以控制删除数据的条数，让操作更安全，还可以减小加锁的范围。

### 案例八：一个死锁的例子

![image-20230315153655989](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/202303151536320.png)

1. session A 启动事务后执行查询语句加 lock in share mode，在索引 c 上加了 next-key lock(5,10] 和间隙锁 (10,15)；
2. session B 的 update 语句也要在索引 c 上加 next-key lock(5,10] ，进入锁等待；
3. 然后 session A 要再插入 (8,8,8) 这一行，被 session B 的间隙锁锁住。由于出现了死锁，InnoDB 让 session B 回滚。

你可能会问，session B 的 next-key lock 不是还没申请成功吗？

其实是这样的，session B 的“加 next-key lock(5,10] ”操作，实际上分成了两步，先是加 (5,10) 的间隙锁，加锁成功；然后加 c=10 的行锁，这时候才被锁住的。

## 22 | MySQL有哪些“饮鸩止渴”提高性能的方法？

### 短连接风暴

正常的短连接模式就是连接到数据库后，执行很少的 SQL 语句就断开，下次需要的时候再重连。如果使用的是短连接，在业务高峰期的时候，就可能出现连接数突然暴涨的情况。

MySQL 建立连接的过程，成本是很高的。除了正常的网络连接三次握手外，还需要做登录权限判断和获得这个连接的数据读写权限。

短连接模型存在一个风险，就是一旦数据库处理得慢一些，连接数就会暴涨。`max_connections `参数，用来控制一个 MySQL 实例同时存在的连接数的上限，超过这个值，系统就会拒绝接下来的连接请求，并报错提示“Too many connections”。

碰到这种情况时，一个比较自然的想法，就是调高 `max_connections` 的值。但这样做是有风险的。因为设计 `max_connections` 这个参数的目的是想保护 `MySQL`，如果我们把它改得太大，让更多的连接都可以进来，那么系统的负载可能会进一步加大，大量的资源耗费在权限验证等逻辑上，结果可能是适得其反，已经连接的线程拿不到 CPU 资源去执行业务的 SQL 请求。

**第一种方法：先处理掉那些占着连接但是不工作的线程。**

`max_connections` 的计算，不是看谁在 running，是只要连着就占用一个计数位置。对于那些不需要保持的连接，我们可以通过` kill connection `主动踢掉。这个行为跟事先设置 `wait_timeout` 的效果是一样的。设置 `wait_timeout` 参数表示的是，一个线程空闲 `wait_timeout` 这么多秒之后，就会被 MySQL 直接断开连接。

在` show processlist` 的结果里，踢掉显示为 sleep 的线程，可能是有损的。

![image-20230317185841990](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/202303171858072.png)

如果断开 session A 的连接，因为这时候 session A 还没有提交，所以 MySQL 只能按照回滚事务来处理；而断开 session B 的连接，就没什么大影响。所以，如果按照优先级来说，你应该优先断开像 session B 这样的事务外空闲的连接。

![image-20230317190759457](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/202303171907536.png)

图中 id=4 和 id=5 的两个会话都是 Sleep 状态。而要看事务具体状态的话，你可以查 information_schema 库的 innodb_trx 表。

![image-20230317191103658](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/202303171911758.png)

这个结果里，trx_mysql_thread_id=4，表示 id=4 的线程还处在事务中

从服务端断开连接使用的是 kill connection + id 的命令， 一个客户端处于 sleep 状态时，它的连接被服务端主动断开后，这个客户端并不会马上知道。直到客户端在发起下一个请求的时候，才会收到这样的报错“ERROR 2013 (HY000): Lost connection to MySQL server during query”。

从数据库端主动断开连接可能是有损的，尤其是有的应用端收到这个错误后，不重新连接，而是直接用这个已经不能用的句柄重试查询。这会导致从应用端看上去，“MySQL 一直没恢复”。

**第二种方法：减少连接过程的消耗。**

有的业务代码会在短时间内先大量申请数据库连接做备用，如果现在数据库确认是被连接行为打挂了，那么一种可能的做法，是让数据库跳过权限验证阶段。

跳过权限验证的方法是：重启数据库，并使用`–skip-grant-tables` 参数启动。这样，整个 MySQL 会跳过所有的权限验证阶段，包括连接过程和语句执行过程在内。

在 MySQL 8.0 版本里，如果你启用`–skip-grant-tables `参数，MySQL 会默认把 `--skip-networking `参数打开，表示这时候数据库只能被本地的客户端连接。可见，MySQL 官方对 `skip-grant-tables `这个参数的安全问题也很重视。

查询问题比较典型的有两类，一类是由新出现的慢查询导致的，一类是由 QPS（每秒查询数）突增导致的。

**慢查询性能问题**

在 MySQL 中，会引发性能问题的慢查询，大体有以下三种可能：

1. 索引没有设计好；
2. SQL 语句没写好；
3. MySQL 选错了索引。

**导致慢查询的第一种可能是，索引没有设计好。**

比较理想的是能够在备库先执行。假设你现在的服务是一主一备，主库 A、备库 B，这个方案的大致流程是这样的：

1. 在备库 B 上执行` set sql_log_bin=off`，也就是不写 `binlog`，然后执行 alter table 语句加上索引；
2. 执行主备切换；这时候主库是 B，备库是 A。
3. 在 A 上执行` set sql_log_bin=off`，然后执行 alter table 语句加上索引。

**导致慢查询的第二种可能是，语句没写好。**

MySQL 5.7 提供了 query_rewrite 功能，可以把输入的一种语句改写成另外一种模式。

比如，语句被错误地写成了 `select * from t where id + 1 = 10000`，你可以通过下面的方式，增加一个语句改写规则。

```mysql
mysql> insert into query_rewrite.rewrite_rules(pattern, replacement, pattern_database) values ("select * from t where id + 1 = ?", "select * from t where id = ? - 1", "db1");

call query_rewrite.flush_rewrite_rules();
```

`call query_rewrite.flush_rewrite_rules() `这个存储过程，是让插入的新规则生效，也就是我们说的“查询重写”。

![img](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/202303171944521.png)

**导致慢查询的第三种可能,MySQL 选错了索引。**

应急方案就是给这个语句加上 force index。

同样地，使用查询重写功能，给原来的语句加上 force index，也可以解决这个问题。

上面我和你讨论的由慢查询导致性能问题的三种可能情况，实际上出现最多的是前两种，即：索引没设计好和语句没写好。而这两种情况，恰恰是完全可以避免的。比如，通过下面这个过程，我们就可以预先发现问题。

1. 上线前，在测试环境，把慢查询日志（slow log）打开，并且把 long_query_time 设置成 0，确保每个语句都会被记录入慢查询日志；
2. 在测试表里插入模拟线上的数据，做一遍回归测试；
3. 观察慢查询日志里每类语句的输出，特别留意 Rows_examined 字段是否与预期一致。（我们在前面文章中已经多次用到过 Rows_examined 方法了，相信你已经动手尝试过了。如果还有不明白的，欢迎给我留言，我们一起讨论）。

如果新增的 SQL 语句不多，手动跑一下就可以。而如果是新项目的话，或者是修改了原有项目的 表结构设计，全量回归测试都是必要的。这时候，你需要工具帮你检查所有的 SQL 语句的返回结果。比如，你可以使用开源工具 pt-query-digest(https://www.percona.com/doc/percona-toolkit/3.0/pt-query-digest.html)。

### QPS 突增问题

1. 一种是由全新业务的 bug 导致的。假设你的 DB 运维是比较规范的，也就是说白名单是一个个加的。这种情况下，如果你能够确定业务方会下掉这个功能，只是时间上没那么快，那么就可以从数据库端直接把白名单去掉。
2. 如果这个新功能使用的是单独的数据库用户，可以用管理员账号把这个用户删掉，然后断开现有连接。这样，这个新功能的连接不成功，由它引发的 QPS 就会变成 0。
3. 如果这个新增的功能跟主体功能是部署在一起的，那么我们只能通过处理语句来限制。这时，我们可以使用上面提到的查询重写功能，把压力最大的 SQL 语句直接重写成"select 1"返回。

当然，这个操作的风险很高，需要你特别细致。它可能存在两个副作用：

1. 如果别的功能里面也用到了这个 SQL 语句模板，会有误伤；
2. 很多业务并不是靠这一个语句就能完成逻辑的，所以如果单独把这一个语句以 select 1 的结果返回的话，可能会导致后面的业务逻辑一起失败。

> 在实际开发中，我们也要尽量避免一些低效的方法，比如避免大量地使用短连接。同时，如果你做业务开发的话，要知道，连接异常断开是常有的事，你的代码里要有正确地重连并重试的机制。

## 23 | MySQL是怎么保证数据不丢的？

只要 redo log 和 binlog 保证持久化到磁盘，就能确保 MySQL 异常重启后，数据可以恢复。

### binlog 的写入机制

其实，`binlog `的写入逻辑：事务执行过程中，先把日志写到 `binlog cache`，事务提交的时候，再把 `binlog cache` 写到 `binlog` 文件中。

一个事务的 `binlog` 是不能被拆开的，因此不论这个事务多大，也要确保一次性写入。这就涉及到了` binlog cache `的保存问题。

> `binlog`写入的前提条件是事务被提交，事务至少进入了`prepare`状态，若此时一个事务的`binlog`如果能拆分写，则意味着在备库执行时，就相当于拆分成了多个事务段执行，此时破坏了事务的原子性，可能导致一些不可预知的问题。

系统给 binlog cache 分配了一片内存，每个线程一个，参数 binlog_cache_size 用于控制单个线程内 binlog cache 所占内存的大小。如果超过了这个参数规定的大小，就要暂存到磁盘。

![img](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/202303211432102.png)

可以看到，每个线程有自己 binlog cache，但是共用同一份 binlog 文件。

* 图中的 write，指的就是指把日志写入到文件系统的 page cache，并没有把数据持久化到磁盘，所以速度比较快。
* 图中的 fsync，才是将数据持久化到磁盘的操作。一般情况下，我们认为 fsync 才占磁盘的 IOPS。

write 和 fsync 的时机，是由参数 sync_binlog 控制的：

1. sync_binlog=0 的时候，表示每次提交事务都只 write，不 fsync
2. sync_binlog=1 的时候，表示每次提交事务都会执行 fsync
3. sync_binlog=N(N>1) 的时候，表示每次提交事务都 write，但累积 N 个事务后才 fsync。

在出现 IO 瓶颈的场景里，将 sync_binlog 设置成一个比较大的值，可以提升性能。在实际的业务场景中，考虑到丢失日志量的可控性，一般不建议将这个参数设成 0，比较常见的是将其设置为 100~1000 中的某个数值。

将 sync_binlog 设置为 N，对应的风险是：如果主机发生异常重启，会丢失最近 N 个事务的 binlog 日志。

### redo log 的写入机制

事务在执行过程中，生成的 redo log 是要先写到 redo log buffer 的。

## 24 | MySQL是怎么保证主备一致的？

## 31 | 误删数据后除了跑路，还能怎么办？

为了找到解决误删数据的更高效的方法，我们需要先对和 MySQL 相关的误删数据，做下分类：

1. 使用 delete 语句误删数据行；
2. 使用 drop table 或者 truncate table 语句误删数据表；
3. 使用 drop database 语句误删数据库；
4. 使用 rm 命令误删整个 MySQL 实例。

### 误删行

如果是使用 delete 语句误删了数据行，可以用 Flashback 工具通过闪回把数据恢复回来。

Flashback 恢复数据的原理，是修改 binlog 的内容，拿回原库重放。而能够使用这个方案的前提是，需要确保 binlog_format=row 和 binlog_row_image=FULL。

具体恢复数据时，对单个事务做如下处理：

* 对于 insert 语句，对应的 binlog event 类型是 Write_rows event，把它改成 Delete_rows event 即可；
* 同理，对于 delete 语句，也是将 Delete_rows event 改为 Write_rows event；
* 而如果是 Update_rows 的话，binlog 里面记录了数据行修改前和修改后的值，对调这两行的位置即可。

如果误操作不是一个，而是多个，会怎么样呢？比如下面三个事务：

```mysql
(A)delete ...
(B)insert ...
(C)update ...
```

现在要把数据库恢复回这三个事务操作之前的状态，用 Flashback 工具解析 binlog 后，写回主库的命令是：

```mysql
(reverse C)update ...
(reverse B)delete ...
(reverse A)insert ...
```

也就是说，如果误删数据涉及到了多个事务的话，需要将事务的顺序调过来再执行。

需要说明的是，我不建议你直接在主库上执行这些操作。

恢复数据比较安全的做法，是恢复出一个备份，或者找一个从库作为临时库，在这个临时库上执行这些操作，然后再将确认过的临时库的数据，恢复回主库。

**如何预防:**

> 把 `sql_safe_updates `参数设置为 on。这样一来，如果我们忘记在 delete 或者 update 语句中写 where 条件，或者 where 条件里面没有包含索引字段的话，这条语句的执行就会报错。
>
> 代码上线前，必须经过 SQL 审计。

设置了 sql_safe_updates=on，如果我真的要把一个小表的数据全部删掉，应该怎么办呢？

如果你确定这个删除操作没问题的话，可以在 delete 语句中加上 where 条件，比如` where id>=0。`

delete 全表是很慢的，需要生成回滚日志、写 redo、写 binlog。所以，从性能角度考虑，你应该优先考虑使用 `truncate table `或者 `drop table `命令。

使用 delete 命令删除的数据，你还可以用 Flashback 来恢复。而使用 truncate /drop table 和 drop database 命令删除的数据，就没办法通过 Flashback 来恢复了。为什么呢？

这是因为，即使我们配置了 binlog_format=row，执行这三个命令时，记录的 binlog 还是 statement 格式。binlog 里面就只有一个 truncate/drop 语句，这些信息是恢复不出数据的。

### 误删库 / 表

备份恢复



## 32 | 为什么还有kill不掉的语句？

执行一个查询的过程中，发现执行时间太久，要放弃继续查询，这时我们就可以用 `kill query `命令，终止这条查询语句。

语句处于锁等待的时候，直接使用 kill 命令也是有效的。

![image-20230322144349460](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/202303221443638.png)

## 34 | 到底可不可以使用join？

在实际生产中，关于 join 语句使用的问题，一般会集中在以下两类：

1. 我们 DBA 不让使用 join，使用 join 有什么问题呢？
2. 如果有两个大小不同的表做 join，应该用哪个表做驱动表呢？

```mysql

CREATE TABLE `t2` (
  `id` int(11) NOT NULL,
  `a` int(11) DEFAULT NULL,
  `b` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `a` (`a`)
) ENGINE=InnoDB;

drop procedure idata;
delimiter ;;
create procedure idata()
begin
  declare i int;
  set i=1;
  while(i<=1000)do
    insert into t2 values(i, i, i);
    set i=i+1;
  end while;
end;;
delimiter ;
call idata();

create table t1 like t2;
insert into t1 (select * from t2 where id<=100)
```

这两个表都有一个主键索引 id 和一个索引 a，字段 b 上无索引。存储过程 idata() 往表 t2 里插入了 1000 行数据，在表 t1 里插入的是 100 行数据。

### Index Nested-Loop Join

```mysql
select * from t1 straight_join t2 on (t1.a=t2.a);
```

如果直接使用 join 语句，MySQL 优化器可能会选择表 t1 或 t2 作为驱动表，这样会影响我们分析 SQL 语句的执行过程。所以，为了便于分析执行过程中的性能问题，我改用 straight_join 让 MySQL 使用固定的连接方式执行查询，这样优化器只会按照我们指定的方式去 join。在这个语句里，t1 是驱动表，t2 是被驱动表。

![img](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/202303221458875.png)

可以看到，在这条语句里，被驱动表 t2 的字段 a 上有索引，join 过程用上了这个索引，因此这个语句的执行流程是这样的：

1. 从表 t1 中读入一行数据 R；
2. 从数据行 R 中，取出 a 字段到表 t2 里去查找；
3. 取出表 t2 中满足条件的行，跟 R 组成一行，作为结果集的一部分；
4. 重复执行步骤 1 到 3，直到表 t1 的末尾循环结束。

![image-20230322150202591](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/202303221502941.png)

1. 对驱动表 t1 做了全表扫描，这个过程需要扫描 100 行；
2. 而对于每一行 R，根据 a 字段去表 t2 查找，走的是树搜索过程。由于我们构造的数据都是一一对应的，因此每次的搜索过程都只扫描一行，也是总共扫描 100 行；
3. 所以，整个执行流程，总扫描行数是 200。

假设不使用 join，那我们就只能用单表查询。我们看看上面这条语句的需求，用单表查询怎么实现。

1. 执行select * from t1，查出表 t1 的所有数据，这里有 100 行；
2. 循环遍历这 100 行数据：
   	1.	从每一行 R 取出字段 a 的值 $R.a；
    	2.	执行select * from t2 where a=$R.a；
    	3.	把返回的结果和 R 构成结果集的一行。

可以看到，在这个查询过程，也是扫描了 200 行，但是总共执行了 101 条语句，比直接 join 多了 100 次交互。除此之外，客户端还要自己拼接 SQL 语句和结果。

**显然，这么做还不如直接 join 好。**

### 怎么选择驱动表？

在这个 join 语句执行过程中，**驱动表是走全表扫描**，而**被驱动表是走树搜索**。

假设被驱动表的行数是 M。每次在被驱动表查一行数据，要先搜索索引 a，再搜索主键索引。每次搜索一棵树近似复杂度是以 2 为底的 M 的对数，记为 log2M，所以在被驱动表上查一行的时间复杂度是 2*log2M。*(因为要回表，所以是2倍)

假设驱动表的行数是 N，执行过程就要扫描驱动表 N 行，然后对于每一行，到被驱动表上匹配一次。因此整个执行过程，近似复杂度是 N + N\*2\*log2M。（n(1+2*log2m)）

> 1. 使用 join 语句，性能比强行拆成多个单表执行 SQL 语句的性能要好；
> 2. 如果使用 join 语句的话，需要让**小表做驱动表**。
>
> 这个结论的前提是“**可以使用被驱动表的索引**”

### Simple Nested-Loop Join

```mysql
select * from t1 straight_join t2 on (t1.a=t2.b);
```

这个 SQL 请求就要扫描表 t2 多达 100 次，总共扫描 100*1000=10 万行。

当然，MySQL 也没有使用这个 Simple Nested-Loop Join 算法，而是使用了另一个叫作“Block Nested-Loop Join”的算法，简称 BNL。

### Block Nested-Loop Join

被驱动表上没有可用的索引，算法的流程是这样的：

1. 把表 t1 的数据读入线程内存 join_buffer 中，由于我们这个语句中写的是 select *，因此是把整个表 t1 放入了内存；
2. 扫描表 t2，把表 t2 中的每一行取出来，跟 join_buffer 中的数据做对比，满足 join 条件的，作为结果集的一部分返回。

![image-20230322152641687](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/202303221526053.png)

![img](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/202303221527839.png)

可以看到，在这个过程中，对表 t1 和 t2 都做了一次全表扫描，因此总的扫描行数是 1100。由于 join_buffer 是以无序数组的方式组织的，因此对表 t2 中的每一行，都要做 100 次判断，总共需要在内存中做的判断次数是：100*1000=10 万次。

假设小表的行数是 N，大表的行数是 M，那么在这个算法里：

* 两个表都做一次全表扫描，所以总的扫描行数是 M+N；
* 内存中的判断次数是 M*N。

> 调换这两个算式中的 M 和 N 没差别，因此**这时候选择大表还是小表做驱动表，执行耗时是一样的。**

**这个例子里表 t1 才 100 行，要是表 t1 是一个大表，join_buffer 放不下怎么办呢？**

join_buffer 的大小是由参数 join_buffer_size 设定的，默认值是 256k。如果放不下表 t1 的所有数据话，策略很简单，就是分段放。我把 join_buffer_size 改成 1200，再执行：

```mysql
select * from t1 straight_join t2 on (t1.a=t2.b);
```

执行过程就变成了：

	1.	扫描表 t1，顺序读取数据行放入 join_buffer 中，放完第 88 行 join_buffer 满了，继续第 2 步；
 	2.	扫描表 t2，把 t2 中的每一行取出来，跟 join_buffer 中的数据做对比，满足 join 条件的，作为结果集的一部分返回；
 	3.	清空 join_buffer；
 	4.	继续扫描表 t1，顺序读取最后的 12 行数据放入 join_buffer 中，继续执行第 2 步。

![image-20230322153732084](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/202303221537458.png)

图中的步骤 4 和 5，表示清空 join_buffer 再复用。

可以看到，这时候由于表 t1 被分成了两次放入 join_buffer 中，导致表 t2 会被扫描两次。虽然分成两次放入 join_buffer，但是判断等值条件的次数还是不变的，依然是 (88+12)*1000=10 万次。

假设，驱动表的数据行数是 N，需要分 K 段才能完成算法流程，被驱动表的数据行数是 M。注意，这里的 K 不是常数，N 越大 K 就会越大，因此把 K 表示为λ\*N，显然λ的取值范围是 (0,1)。所以，在这个算法的执行过程中：

* 扫描行数是 N+λ*N*M；(N + K*M)
* 内存判断 N*M 次。

内存判断次数是不受选择哪个表作为驱动表影响的。而考虑到扫描行数，在 M 和 N 大小确定的情况下，N 小一些，整个算式的结果会更小。

所以结论是，**应该让小表当驱动表**。

**第一个问题：能不能使用 join 语句？**

> 1. 如果可以使用 Index Nested-Loop Join 算法，也就是说可以用上被驱动表上的索引，其实是没问题的；
> 2. 如果使用 Block Nested-Loop Join 算法，扫描行数就会过多。尤其是在大表上的 join 操作，这样可能要扫描被驱动表很多次，会占用大量的系统资源。所以这种 join 尽量不要用。

所以你在判断要不要使用 join 语句时，就是看 explain 结果里面，Extra 字段里面有没有出现“Block Nested Loop”字样。

**第二个问题是：如果要使用 join，应该选择大表做驱动表还是选择小表做驱动表？**

> 1. 如果是 Index Nested-Loop Join 算法，应该选择小表做驱动表；
> 2. 如果是 Block Nested-Loop Join 算法：
>    * 在 join_buffer_size 足够大的时候，是一样的；
>    * 在 join_buffer_size 不够大的时候（这种情况更常见），应该选择小表做驱动表。
>
> 所以，这个问题的结论就是，总是应该使用小表做驱动表。

如果我在语句的 where 条件加上 t2.id<=50 这个限定条件，再来看下这两条语句：(t1数据100条，t2数据1000条)

```mysql
select * from t1 straight_join t2 on (t1.b=t2.b) where t2.id<=50;
select * from t2 straight_join t1 on (t1.b=t2.b) where t2.id<=50;
```

注意，为了让两条语句的被驱动表都用不上索引，所以 join 字段都使用了没有索引的字段 b。

但如果是用第二个语句的话，join_buffer 只需要放入 t2 的前 50 行，显然是更好的。所以这里，“**t2 的前 50 行”是那个相对小的表，也就是“小表”**。

```mysql
select t1.b,t2.* from  t1  straight_join t2 on (t1.b=t2.b) where t2.id<=100;
select t1.b,t2.* from  t2  straight_join t1 on (t1.b=t2.b) where t2.id<=100;
```

这个例子里，表 t1 和 t2 都是只有 100 行参加 join。但是，这两条语句每次查询放入 join_buffer 中的数据是不一样的：

* 表 t1 只查字段 b，因此如果把 t1 放到 join_buffer 中，则 join_buffer 中只需要放入 b 的值；
* 表 t2 需要查所有的字段，因此如果把表 t2 放到 join_buffer 中的话，就需要放入三个字段 id、a 和 b。

这里，我们应该选择表 t1 作为驱动表。也就是说在这个例子里，“只需要一列参与 join 的表 t1”是那个相对小的表。

> 在决定哪个表做驱动表的时候，应该是两个表按照各自的条件过滤，过滤完成之后，计算参与 join 的各个字段的总数据量，数据量小的那个表，就是“小表”，应该作为驱动表。

### 总结

1. 如果可以使用被驱动表的索引，join 语句还是有其优势的；
2. 不能使用被驱动表的索引，只能使用 Block Nested-Loop Join 算法，这样的语句就尽量不要使用；
3. 在使用 join 的时候，应该让小表做驱动表。

## 35 | join语句怎么优化？

```mysql

create table t1(id int primary key, a int, b int, index(a));
create table t2 like t1;
drop procedure idata;
delimiter ;;
create procedure idata()
begin
  declare i int;
  set i=1;
  while(i<=1000)do
    insert into t1 values(i, 1001-i, i);
    set i=i+1;
  end while;
  
  set i=1;
  while(i<=1000000)do
    insert into t2 values(i, i, i);
    set i=i+1;
  end while;

end;;
delimiter ;
call idata();
```

​	在表 t1 里，插入了 1000 行数据，每一行的 a=1001-id 的值。也就是说，表 t1 中字段 a 是逆序的。同时，我在表 t2 中插入了 100 万行数据

### Multi-Range Read 优化

Multi-Range Read 优化 (MRR)。这个优化的主要目的是尽量使用顺序读盘。

回表是指，InnoDB 在普通索引 a 上查到主键 id 的值后，再根据一个个主键 id 的值到主键索引上去查整行数据的过程。

```mysql
select * from t1 where a>=1 and a<=100;
```

主键索引是一棵 B+ 树，在这棵树上，每次只能根据一个主键 id 查到一行数据。因此，**回表肯定是一行行搜索主键索引的**，基本流程如图 1 所示。

![image-20230323165631214](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/202303231656556.png)

如果随着 a 的值递增顺序查询的话，id 的值就变成随机的，那么就会出现随机访问，性能相对较差。虽然“按行查”这个机制不能改，但是调整查询的顺序，还是能够加速的。

**因为大多数的数据都是按照主键递增顺序插入得到的，所以我们可以认为，如果按照主键的递增顺序查询的话，对磁盘的读比较接近顺序读，能够提升读性能。**

这，就是 MRR 优化的设计思路。此时，语句的执行流程变成了这样：

1. 根据索引 a，定位到满足条件的记录，将 id 值放入 read_rnd_buffer 中 ;
2. 将 read_rnd_buffer 中的 id 进行递增排序；
3. 排序后的 id 数组，依次到主键 id 索引中查记录，并作为结果返回。

这里，`read_rnd_buffer` 的大小是由 `read_rnd_buffer_size` 参数控制的。如果步骤 1 中，`read_rnd_buffer` 放满了，就会先执行完步骤 2 和 3，然后清空 `read_rnd_buffer`。之后继续找索引 a 的下个记录，并继续循环。

如果你想要稳定地使用 MRR 优化的话，需要设置set `optimizer_switch="mrr_cost_based=off"`。（官方文档的说法，是现在的优化器策略，判断消耗的时候，会更倾向于不使用 MRR，把 mrr_cost_based 设置为 off，就是固定使用 MRR 了。）

![image-20230323171330282](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/202303231713644.png)

![img](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/202303231715419.png)

我们可以看到 Extra 字段多了 Using MRR，表示的是用上了 MRR 优化。而且，由于我们在 read_rnd_buffer 中按照 id 做了排序，所以最后得到的结果集也是按照主键 id 递增顺序的，也就是与图 1 结果集中行的顺序相反。

**MRR 能够提升性能的核心**在于，这条查询语句在索引 a 上做的是一个范围查询（也就是说，这是一个多值查询），可以得到足够多的主键 id。这样通过排序以后，再去主键索引查数据，才能体现出“顺序性”的优势。

### Batched Key Access

![image-20230323183442196](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/202303231834563.png)

NLJ 算法执行的逻辑是：从驱动表 t1，一行行地取出 a 的值，再到被驱动表 t2 去做 join。也就是说，对于表 t2 来说，每次都是匹配一个值。这时，MRR 的优势就用不上了。

那怎么才能一次性地多传些值给表 t2 呢？方法就是，从表 t1 里一次性地多拿些行出来，一起传给表 t2。

既然如此，我们就把表 t1 的数据取出来一部分，先放到一个临时内存。这个临时内存不是别人，就是 join_buffer。

我们知道 join_buffer 在 BNL 算法里的作用，是暂存驱动表的数据。但是在 NLJ 算法里并没有用。那么，我们刚好就可以复用 join_buffer 到 BKA 算法中。如图 5 所示，是上面的 NLJ 算法优化后的 BKA 算法的流程。

![image-20230323184816717](https://trpora-1300527744.cos.ap-chongqing.myqcloud.com/img/202303231848109.png)